{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Nautobot VPN APP","text":"<p>A Nautobot plugin designed to model, visualize, and manage VPN infrastructure, including IPSec tunnels, IKE gateways, crypto profiles, and dynamic topology diagrams sourced from Neo4j.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>IKE Gateway and IPSec Tunnel modeling</li> <li>Inline or default crypto profile selection</li> <li>Dynamic tunnel provisioning form with interface auto-selection</li> <li>Topology visualization via Neo4j + Cytoscape</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Nautobot &gt;= 2.2.0</li> <li>Python &gt;= 3.8</li> <li>Neo4j &gt;= 5.0 (for topology view)</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#1-install-via-pip","title":"1. Install via pip","text":"<pre><code>pip install nautobot-app-vpn\n</code></pre>"},{"location":"#2-enable-the-plugin","title":"2. Enable the plugin","text":"<p>In your <code>nautobot_config.py</code>, add to <code>PLUGINS</code> and configure Neo4j settings:</p> <pre><code>PLUGINS = [\n    \"nautobot_app_vpn\",\n    # ...\n]\n\nPLUGINS_CONFIG = {\n    \"nautobot_app_vpn\": {\n        \"neo4j\": {\n            \"uri\": \"bolt://neo4j:7687\",\n            \"user\": \"neo4j\",\n            \"password\": \"testneo4j\",  # Change this\n        }\n    }\n}\n</code></pre>"},{"location":"#dockercompose-setup-optional","title":"Docker/Compose Setup (Optional)","text":"<p>If you are using <code>docker-compose</code>, include this plugin in your <code>plugin_requirements.txt</code>:</p> <pre><code>nautobot-app-vpn\n</code></pre> <p>Then rebuild Nautobot:</p> <pre><code>docker-compose build nautobot\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#topology-view","title":"Topology View","text":"<p>The plugin provides a Neo4j-powered dashboard under Plugins &gt; VPN Dashboard, enabling visualization of active IPSec tunnels and their metadata.</p>"},{"location":"#forms-for-provisioning","title":"Forms for Provisioning","text":"<ul> <li>Auto-select interfaces based on ISP zone tags</li> <li>Auto-populate IPs from synced device data</li> <li>Support dynamic IP tunnels</li> <li>Create or select IKE/IPsec crypto profiles</li> </ul>"},{"location":"#screenshots","title":"Screenshots","text":""},{"location":"#development","title":"Development","text":""},{"location":"#clone-and-install-in-editable-mode","title":"Clone and install in editable mode:","text":"<pre><code>git clone https://github.com/npolisetty26/nautobot-app-vpn.git\ncd nautobot-app-vpn\npoetry install\n</code></pre>"},{"location":"#run-linters-locally","title":"Run linters locally","text":"<pre><code>ruff check .\nyamllint .\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>Pull requests are welcome! Please ensure code follows Nautobot plugin guidelines and passes all checks.</p>"},{"location":"#license","title":"License","text":"<p>Apache License 2.0. See LICENSE for details.</p>"},{"location":"#author","title":"Author","text":"<p>Maintained by @npolisetty26</p>"},{"location":"admin/compatibility_matrix/","title":"Compatibility Matrix","text":"<p>Developer Note - Remove Me!</p> <p>Explain how the release models of the app and of Nautobot work together, how releases are supported, how features and older releases are deprecated etc.</p> VPN APP Version Nautobot First Support Version Nautobot Last Support Version 1.0.X 2.4.0 2.99.99"},{"location":"admin/install/","title":"Installing the App in Nautobot","text":"<p>Here you will find detailed instructions on how to install and configure the App within your Nautobot environment.</p> <p>Developer Note - Remove Me!</p> <p>Detailed instructions on installing the App. You will need to update this section based on any additional dependencies or prerequisites.</p>"},{"location":"admin/install/#prerequisites","title":"Prerequisites","text":"<ul> <li>The app is compatible with Nautobot 2.0.0 and higher.</li> <li>Databases supported: PostgreSQL, MySQL</li> </ul> <p>Note</p> <p>Please check the dedicated page for a full compatibility matrix and the deprecation policy.</p>"},{"location":"admin/install/#access-requirements","title":"Access Requirements","text":"<p>Developer Note - Remove Me!</p> <p>What external systems (if any) it needs access to in order to work.</p>"},{"location":"admin/install/#install-guide","title":"Install Guide","text":"<p>Note</p> <p>Apps can be installed from the Python Package Index or locally. See the Nautobot documentation for more details. The pip package name for this app is <code>nautobot_app_vpn</code>.</p> <p>The app is available as a Python package via PyPI and can be installed with <code>pip</code>:</p> <pre><code>pip install nautobot_app_vpn\n</code></pre> <p>To ensure VPN APP is automatically re-installed during future upgrades, create a file named <code>local_requirements.txt</code> (if not already existing) in the Nautobot root directory (alongside <code>requirements.txt</code>) and list the <code>nautobot_app_vpn</code> package:</p> <pre><code>echo nautobot_app_vpn &gt;&gt; local_requirements.txt\n</code></pre> <p>Once installed, the app needs to be enabled in your Nautobot configuration. The following block of code below shows the additional configuration required to be added to your <code>nautobot_config.py</code> file:</p> <ul> <li>Append <code>\"nautobot_app_vpn\"</code> to the <code>PLUGINS</code> list.</li> <li>Append the <code>\"nautobot_app_vpn\"</code> dictionary to the <code>PLUGINS_CONFIG</code> dictionary and override any defaults.</li> </ul> <pre><code># In your nautobot_config.py\nPLUGINS = [\"nautobot_app_vpn\"]\n\n# PLUGINS_CONFIG = {\n#   \"nautobot_app_vpn\": {\n#     ADD YOUR SETTINGS HERE\n#   }\n# }\n</code></pre> <p>Once the Nautobot configuration is updated, run the Post Upgrade command (<code>nautobot-server post_upgrade</code>) to run migrations and clear any cache:</p> <pre><code>nautobot-server post_upgrade\n</code></pre> <p>Then restart (if necessary) the Nautobot services which may include:</p> <ul> <li>Nautobot</li> <li>Nautobot Workers</li> <li>Nautobot Scheduler</li> </ul> <pre><code>sudo systemctl restart nautobot nautobot-worker nautobot-scheduler\n</code></pre>"},{"location":"admin/install/#app-configuration","title":"App Configuration","text":"<p>Developer Note - Remove Me!</p> <p>Any configuration required to get the App set up. Edit the table below as per the examples provided.</p> <p>The app behavior can be controlled with the following list of settings:</p> Key Example Default Description <code>enable_backup</code> <code>True</code> <code>True</code> A boolean to represent whether or not to run backup configurations within the app. <code>platform_slug_map</code> <code>{\"cisco_wlc\": \"cisco_aireos\"}</code> <code>None</code> A dictionary in which the key is the platform slug and the value is what netutils uses in any \"network_os\" parameter. <code>per_feature_bar_width</code> <code>0.15</code> <code>0.15</code> The width of the table bar within the overview report"},{"location":"admin/uninstall/","title":"Uninstall the App from Nautobot","text":"<p>Here you will find any steps necessary to cleanly remove the App from your Nautobot environment.</p>"},{"location":"admin/uninstall/#database-cleanup","title":"Database Cleanup","text":"<p>Prior to removing the app from the <code>nautobot_config.py</code>, run the following command to roll back any migration specific to this app.</p> <pre><code>nautobot-server migrate nautobot_app_vpn zero\n</code></pre> <p>Developer Note - Remove Me!</p> <p>Any other cleanup operations to ensure the database is clean after the app is removed. Is there anything else that needs cleaning up, such as CFs, relationships, etc. if they're no longer desired?</p>"},{"location":"admin/uninstall/#remove-app-configuration","title":"Remove App configuration","text":"<p>Remove the configuration you added in <code>nautobot_config.py</code> from <code>PLUGINS</code> &amp; <code>PLUGINS_CONFIG</code>.</p>"},{"location":"admin/uninstall/#uninstall-the-package","title":"Uninstall the package","text":"<pre><code>$ pip3 uninstall nautobot_app_vpn\n</code></pre>"},{"location":"admin/upgrade/","title":"Upgrading the App","text":"<p>Here you will find any steps necessary to upgrade the App in your Nautobot environment.</p>"},{"location":"admin/upgrade/#upgrade-guide","title":"Upgrade Guide","text":"<p>Developer Note - Remove Me!</p> <p>Add more detailed steps on how the app is upgraded in an existing Nautobot setup and any version specifics (such as upgrading between major versions with breaking changes).</p> <p>When a new release comes out it may be necessary to run a migration of the database to account for any changes in the data models used by this app. Execute the command <code>nautobot-server post-upgrade</code> within the runtime environment of your Nautobot installation after updating the <code>nautobot_app_vpn</code> package via <code>pip</code>.</p>"},{"location":"admin/release_notes/","title":"Release Notes","text":"<p>All the published release notes can be found via the navigation menu. All patch releases are included in the same minor release (e.g. <code>v1.2</code>) document.</p>"},{"location":"admin/release_notes/version_1.0/","title":"v1.0 Release Notes","text":"<p>Developer Note - Remove Me!</p> <p>Guiding Principles:</p> <ul> <li>Changelogs are for humans, not machines.</li> <li>There should be an entry for every single version.</li> <li>The same types of changes should be grouped.</li> <li>Versions and sections should be linkable.</li> <li>The latest version comes first.</li> <li>The release date of each version is displayed.</li> <li>Mention whether you follow Semantic Versioning.</li> </ul> <p>Types of changes:</p> <ul> <li><code>Added</code> for new features.</li> <li><code>Changed</code> for changes in existing functionality.</li> <li><code>Deprecated</code> for soon-to-be removed features.</li> <li><code>Removed</code> for now removed features.</li> <li><code>Fixed</code> for any bug fixes.</li> <li><code>Security</code> in case of vulnerabilities.</li> </ul> <p>This document describes all new features and changes in the release <code>1.0</code>. The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"admin/release_notes/version_1.0/#release-overview","title":"Release Overview","text":"<ul> <li>Major features or milestones</li> <li>Achieved in this <code>x.y</code> release</li> <li>Changes to compatibility with Nautobot and/or other apps, libraries etc.</li> </ul>"},{"location":"admin/release_notes/version_1.0/#v101-2021-09-08","title":"[v1.0.1] - 2021-09-08","text":""},{"location":"admin/release_notes/version_1.0/#added","title":"Added","text":""},{"location":"admin/release_notes/version_1.0/#changed","title":"Changed","text":""},{"location":"admin/release_notes/version_1.0/#fixed","title":"Fixed","text":"<ul> <li>#123 Fixed Tag filtering not working in job launch form</li> </ul>"},{"location":"admin/release_notes/version_1.0/#v100-2021-08-03","title":"[v1.0.0] - 2021-08-03","text":""},{"location":"admin/release_notes/version_1.0/#added_1","title":"Added","text":""},{"location":"admin/release_notes/version_1.0/#changed_1","title":"Changed","text":""},{"location":"admin/release_notes/version_1.0/#fixed_1","title":"Fixed","text":""},{"location":"dev/arch_decision/","title":"Architecture Decision Records","text":"<p>The intention is to document deviations from a standard Model View Controller (MVC) design.</p> <p>Developer Note - Remove Me!</p> <p>Optional page, remove if not applicable. For examples see Golden Config.</p>"},{"location":"dev/contributing/","title":"Contributing to the App","text":"<p>The project is packaged with a light development environment based on <code>docker-compose</code> to help with the local development of the project and to run tests.</p> <p>The project is following Network to Code software development guidelines and is leveraging the following:</p> <ul> <li>Python linting and formatting: <code>pylint</code> and <code>ruff</code>.</li> <li>YAML linting is done with <code>yamllint</code>.</li> <li>Django unit test to ensure the app is working properly.</li> </ul> <p>Documentation is built using mkdocs. The Docker based development environment automatically starts a container hosting a live version of the documentation website on http://localhost:8001 that auto-refreshes when you make any changes to your local files.</p>"},{"location":"dev/contributing/#creating-changelog-fragments","title":"Creating Changelog Fragments","text":"<p>All pull requests to <code>next</code> or <code>develop</code> must include a changelog fragment file in the <code>./changes</code> directory. To create a fragment, use your GitHub issue number and fragment type as the filename. For example, <code>2362.added</code>. Valid fragment types are <code>added</code>, <code>changed</code>, <code>deprecated</code>, <code>fixed</code>, <code>removed</code>, and <code>security</code>. The change summary is added to the file in plain text. Change summaries should be complete sentences, starting with a capital letter and ending with a period, and be in past tense. Each line of the change fragment will generate a single change entry in the release notes. Use multiple lines in the same file if your change needs to generate multiple release notes in the same category. If the change needs to create multiple entries in separate categories, create multiple files.</p> <p>Example</p> <p>Wrong changes/1234.fixed<pre><code>fix critical bug in documentation\n</code></pre></p> <p>Right changes/1234.fixed<pre><code>Fixed critical bug in documentation.\n</code></pre></p> <p>Multiple Entry Example</p> <p>This will generate 2 entries in the <code>fixed</code> category and one entry in the <code>changed</code> category.</p> changes/1234.fixed<pre><code>Fixed critical bug in documentation.\nFixed release notes generation.\n</code></pre> changes/1234.changed<pre><code>Changed release notes generation.\n</code></pre>"},{"location":"dev/contributing/#branching-policy","title":"Branching Policy","text":"<p>The branching policy includes the following tenets:</p> <ul> <li>The <code>develop</code> branch is the branch of the next major and minor paired version planned.</li> <li>PRs intended to add new features should be sourced from the <code>develop</code> branch.</li> <li>PRs intended to fix issues in the Nautobot LTM compatible release should be sourced from the latest <code>ltm-&lt;major.minor&gt;</code> branch instead of <code>develop</code>.</li> </ul> <p>VPN APP will observe semantic versioning, as of 1.0. This may result in a quick turnaround in minor versions to keep pace with an ever-growing feature set.</p>"},{"location":"dev/contributing/#backporting-to-older-releases","title":"Backporting to Older Releases","text":"<p>If you are backporting any fixes to a prior major or minor version of this app, please open an issue, comment on an existing issue, or post in the Network to Code Slack (channel <code>#nautobot</code>).</p> <p>We will create a <code>release-X.Y</code> branch for you to open your PR against and cut a new release once the PR is successfully merged.</p>"},{"location":"dev/contributing/#release-policy","title":"Release Policy","text":"<p>VPN APP has currently no intended scheduled release schedule, and will release new features in minor versions.</p> <p>The steps taken by maintainers when creating a new release are documented in the release checklist.</p>"},{"location":"dev/dev_environment/","title":"Building Your Development Environment","text":""},{"location":"dev/dev_environment/#quickstart-guide","title":"Quickstart Guide","text":"<p>The development environment can be used in two ways:</p> <ol> <li>(Recommended) All services, including Nautobot, are spun up using Docker containers and a volume mount so you can develop locally.</li> <li>With a local Poetry environment if you wish to develop outside of Docker, with the caveat of using external services provided by Docker for the database (PostgreSQL by default, MySQL optionally) and Redis services.</li> </ol> <p>This is a quick reference guide if you're already familiar with the development environment provided, which you can read more about later in this document.</p>"},{"location":"dev/dev_environment/#invoke","title":"Invoke","text":"<p>The Invoke library is used to provide some helper commands based on the environment. There are a few configuration parameters which can be passed to Invoke to override the default configuration:</p> <ul> <li><code>nautobot_ver</code>: the version of Nautobot to use as a base for any built docker containers (default: 2.0.0)</li> <li><code>project_name</code>: the default docker compose project name (default: <code>nautobot_app_vpn</code>)</li> <li><code>python_ver</code>: the version of Python to use as a base for any built docker containers (default: 3.11)</li> <li><code>local</code>: a boolean flag indicating if invoke tasks should be run on the host or inside the docker containers (default: False, commands will be run in docker containers)</li> <li><code>compose_dir</code>: the full path to a directory containing the project compose files</li> <li><code>compose_files</code>: a list of compose files applied in order (see Multiple Compose files for more information)</li> </ul> <p>Using Invoke these configuration options can be overridden using several methods. Perhaps the simplest is setting an environment variable <code>INVOKE_NAUTOBOT_APP_VPN_VARIABLE_NAME</code> where <code>VARIABLE_NAME</code> is the variable you are trying to override. The only exception is <code>compose_files</code>, because it is a list it must be overridden in a YAML file. There is an example <code>invoke.yml</code> (<code>invoke.example.yml</code>) in this directory which can be used as a starting point.</p>"},{"location":"dev/dev_environment/#docker-development-environment","title":"Docker Development Environment","text":"<p>Tip</p> <p>This is the recommended option for development.</p> <p>This project is managed by Python Poetry and has a few requirements to setup your development environment:</p> <ol> <li>Install Poetry, see the Poetry documentation for your operating system.</li> <li>Install Docker, see the Docker documentation for your operating system.</li> <li>Install Docker-compose, see the Docker-compose documentation for your operation system.</li> </ol> <p>Once you have Poetry and Docker installed you can run the following commands (in the root of the repository) to install all other development dependencies in an isolated Python virtual environment:</p> <pre><code>poetry shell\npoetry install\ninvoke build\ninvoke start\n</code></pre> <p>The Nautobot server can now be accessed at http://localhost:8080 and the live documentation at http://localhost:8001.</p> <p>To either stop or destroy the development environment use the following options.</p> <ul> <li>invoke stop - Stop the containers, but keep all underlying systems intact</li> <li>invoke destroy - Stop and remove all containers, volumes, etc. (This results in data loss due to the volume being deleted)</li> </ul>"},{"location":"dev/dev_environment/#local-poetry-development-environment","title":"Local Poetry Development Environment","text":"<ul> <li>Create an <code>invoke.yml</code> file with the following contents at the root of the repo and edit as necessary</li> </ul> <pre><code>---\nnautobot_app_vpn:\n  local: true\n</code></pre> <p>Run the following commands:</p> <pre><code>poetry shell\npoetry install --extras nautobot\nexport $(cat development/development.env | xargs)\nexport $(cat development/creds.env | xargs)\ninvoke start &amp;&amp; sleep 5\nnautobot-server migrate\n</code></pre> <p>Note</p> <p>If you want to develop on the latest develop branch of Nautobot, run the following command: <code>poetry add --optional git+https://github.com/nautobot/nautobot@develop</code>. After the <code>@</code> symbol must match either a branch or a tag.</p> <p>You can now run <code>nautobot-server</code> commands as you would from the Nautobot documentation for example to start the development server:</p> <pre><code>nautobot-server runserver 0.0.0.0:8080 --insecure\n</code></pre> <p>Nautobot server can now be accessed at http://localhost:8080.</p> <p>It is typically recommended to launch the Nautobot runserver command in a separate shell so you can keep developing and manage the webserver separately.</p>"},{"location":"dev/dev_environment/#updating-the-documentation","title":"Updating the Documentation","text":"<p>Documentation dependencies are pinned to exact versions to ensure consistent results. For the development environment, they are defined in the <code>pyproject.toml</code> file.</p> <p>If you need to update any of the documentation dependencies to a newer version, make sure you copy the exact same versions pinned in <code>pyproject.toml</code> to the <code>docs/requirements.txt</code> file as well. The latter is used in the automated build pipeline on ReadTheDocs to build the live version of the documentation.</p>"},{"location":"dev/dev_environment/#cli-helper-commands","title":"CLI Helper Commands","text":"<p>The project features a CLI helper based on Invoke to help setup the development environment. The commands are listed below in 3 categories:</p> <ul> <li><code>dev environment</code></li> <li><code>utility</code></li> <li><code>testing</code></li> </ul> <p>Each command can be executed with <code>invoke &lt;command&gt;</code>. All commands support the arguments <code>--nautobot-ver</code> and <code>--python-ver</code> if you want to manually define the version of Python and Nautobot to use. Each command also has its own help <code>invoke &lt;command&gt; --help</code></p>"},{"location":"dev/dev_environment/#local-development-environment","title":"Local Development Environment","text":"<pre><code>  build            Build all docker images.\n  debug            Start Nautobot and its dependencies in debug mode.\n  destroy          Destroy all containers and volumes.\n  restart          Restart Nautobot and its dependencies in detached mode.\n  start            Start Nautobot and its dependencies in detached mode.\n  stop             Stop Nautobot and its dependencies.\n</code></pre>"},{"location":"dev/dev_environment/#utility","title":"Utility","text":"<pre><code>  cli              Launch a bash shell inside the running Nautobot container.\n  create-user      Create a new user in django (default: admin), will prompt for password.\n  makemigrations   Run Make Migration in Django.\n  nbshell          Launch a nbshell session.\n</code></pre>"},{"location":"dev/dev_environment/#testing","title":"Testing","text":"<pre><code>  ruff             Run ruff to perform code formatting and/or linting.\n  pylint           Run pylint code analysis.\n  markdownlint     Run pymarkdown linting.\n  tests            Run all tests for this app.\n  unittest         Run Django unit tests for the app.\n</code></pre>"},{"location":"dev/dev_environment/#project-overview","title":"Project Overview","text":"<p>This project provides the ability to develop and manage the Nautobot server locally (with supporting services being Dockerized) or by using only Docker containers to manage Nautobot. The main difference between the two environments is the ability to debug and use pdb when developing locally. Debugging with pdb within the Docker container is more complicated, but can still be accomplished by either entering into the container (via <code>docker exec</code>) or attaching your IDE to the container and running the Nautobot service manually within the container.</p> <p>The upside to having the Nautobot service handled by Docker rather than locally is that you do not have to manage the Nautobot server. The Docker logs provide the majority of the information you will need to help troubleshoot, while getting started quickly and not requiring you to perform several manual steps and remembering to have the Nautobot server running in a separate terminal while you develop.</p> <p>Note</p> <p>The local environment still uses Docker containers for the supporting services (Postgres, Redis, and RQ Worker), but the Nautobot server is handled locally by you, the developer.</p> <p>Follow the directions below for the specific development environment that you choose.</p>"},{"location":"dev/dev_environment/#poetry","title":"Poetry","text":"<p>Poetry is used in lieu of the \"virtualenv\" commands and is leveraged in both environments. The virtual environment will provide all of the Python packages required to manage the development environment such as Invoke. See the Local Development Environment section to see how to install Nautobot if you're going to be developing locally (i.e. not using the Docker container).</p> <p>The <code>pyproject.toml</code> file outlines all of the relevant dependencies for the project:</p> <ul> <li><code>tool.poetry.dependencies</code> - the main list of dependencies.</li> <li><code>tool.poetry.group.dev.dependencies</code> - development dependencies, to facilitate linting, testing, and documentation building.</li> </ul> <p>The <code>poetry shell</code> command is used to create and enable a virtual environment managed by Poetry, so all commands ran going forward are executed within the virtual environment. This is similar to running the <code>source venv/bin/activate</code> command with virtualenvs. To install project dependencies in the virtual environment, you should run <code>poetry install</code> - this will install both project and development dependencies.</p> <p>For more details about Poetry and its commands please check out its online documentation.</p>"},{"location":"dev/dev_environment/#full-docker-development-environment","title":"Full Docker Development Environment","text":"<p>This project is set up with a number of Invoke tasks consumed as simple CLI commands to get developing fast. You'll use a few <code>invoke</code> commands to get your environment up and running.</p>"},{"location":"dev/dev_environment/#copy-the-credentials-file-for-nautobot","title":"Copy the credentials file for Nautobot","text":"<p>First, you may create/overwrite the <code>development/creds.env</code> file - it stores a bunch of private information such as passwords and tokens for your local Nautobot install. You can make a copy of the <code>development/creds.example.env</code> and modify it to suit you.</p> <pre><code>cp development/creds.example.env development/creds.env\n</code></pre>"},{"location":"dev/dev_environment/#invoke-building-the-docker-image","title":"Invoke - Building the Docker Image","text":"<p>The first thing you need to do is build the necessary Docker image for Nautobot that installs the specific <code>nautobot_ver</code>. The image is used for Nautobot and the Celery worker service used by Docker Compose.</p> <pre><code>\u279c invoke build\n... &lt;omitted for brevity&gt;\n#14 exporting to image\n#14 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00\n#14 exporting layers\n#14 exporting layers 1.2s done\n#14 writing image sha256:2d524bc1665327faa0d34001b0a9d2ccf450612bf8feeb969312e96a2d3e3503 done\n#14 naming to docker.io/nautobot_app_vpn/nautobot:2.0.0-py3.11 done\n</code></pre>"},{"location":"dev/dev_environment/#invoke-starting-the-development-environment","title":"Invoke - Starting the Development Environment","text":"<p>Next, you need to start up your Docker containers.</p> <pre><code>\u279c invoke start\nStarting Nautobot in detached mode...\nRunning docker-compose command \"up --detach\"\nCreating network \"nautobot_app_vpn_default\" with the default driver\nCreating volume \"nautobot_app_vpn_postgres_data\" with default driver\nCreating nautobot_app_vpn_redis_1 ...\nCreating nautobot_app_vpn_docs_1  ...\nCreating nautobot_app_vpn_postgres_1 ...\nCreating nautobot_app_vpn_postgres_1 ... done\nCreating nautobot_app_vpn_redis_1    ... done\nCreating nautobot_app_vpn_nautobot_1 ...\nCreating nautobot_app_vpn_docs_1     ... done\nCreating nautobot_app_vpn_nautobot_1 ... done\nCreating nautobot_app_vpn_worker_1   ...\nCreating nautobot_app_vpn_worker_1   ... done\nDocker Compose is now in the Docker CLI, try `docker compose up`\n</code></pre> <p>This will start all of the Docker containers used for hosting Nautobot. You should see the following containers running after <code>invoke start</code> is finished.</p> <pre><code>\u279c docker ps\n****CONTAINER ID   IMAGE                            COMMAND                  CREATED          STATUS          PORTS                                       NAMES\nee90fbfabd77   nautobot_app_vpn/nautobot:2.0.0-py3.11  \"nautobot-server rqw\u2026\"   16 seconds ago   Up 13 seconds                                               nautobot_app_vpn_worker_1\nb8adb781d013   nautobot_app_vpn/nautobot:2.0.0-py3.11  \"/docker-entrypoint.\u2026\"   20 seconds ago   Up 15 seconds   0.0.0.0:8080-&gt;8080/tcp, :::8080-&gt;8080/tcp   nautobot_app_vpn_nautobot_1\nd64ebd60675d   nautobot_app_vpn/nautobot:2.0.0-py3.11  \"mkdocs serve -v -a \u2026\"   25 seconds ago   Up 18 seconds   0.0.0.0:8001-&gt;8080/tcp, :::8001-&gt;8080/tcp   nautobot_app_vpn_docs_1\ne72d63129b36   postgres:13-alpine               \"docker-entrypoint.s\u2026\"   25 seconds ago   Up 19 seconds   0.0.0.0:5432-&gt;5432/tcp, :::5432-&gt;5432/tcp   nautobot_app_vpn_postgres_1\n96c6ff66997c   redis:6-alpine                   \"docker-entrypoint.s\u2026\"   25 seconds ago   Up 21 seconds   0.0.0.0:6379-&gt;6379/tcp, :::6379-&gt;6379/tcp   nautobot_app_vpn_redis_1\n</code></pre> <p>Once the containers are fully up, you should be able to open up a web browser, and view:</p> <ul> <li>The Nautobot homepage at http://localhost:8080</li> <li>A live version of the documentation at http://localhost:8001</li> </ul> <p>Note</p> <p>Sometimes the containers take a minute to fully spin up. If the page doesn't load right away, wait a minute and try again.</p>"},{"location":"dev/dev_environment/#invoke-creating-a-superuser","title":"Invoke - Creating a Superuser","text":"<p>The Nautobot development image will automatically provision a super user when specifying the following variables within <code>creds.env</code> which is the default when copying <code>creds.example.env</code> to <code>creds.env</code>.</p> <ul> <li><code>NAUTOBOT_CREATE_SUPERUSER=true</code></li> <li><code>NAUTOBOT_SUPERUSER_API_TOKEN=0123456789abcdef0123456789abcdef01234567</code></li> <li><code>NAUTOBOT_SUPERUSER_PASSWORD=admin</code></li> </ul> <p>Note</p> <p>The default username is admin, but can be overridden by specifying NAUTOBOT_SUPERUSER_USERNAME.</p> <p>If you need to create additional superusers, run the follow commands.</p> <pre><code>\u279c invoke createsuperuser\nRunning docker-compose command \"ps --services --filter status=running\"\nRunning docker-compose command \"exec nautobot nautobot-server createsuperuser --username admin\"\nError: That username is already taken.\nUsername: ntc\nEmail address: ntc@networktocode.com\nPassword:\nPassword (again):\nSuperuser created successfully.\n</code></pre>"},{"location":"dev/dev_environment/#invoke-stopping-the-development-environment","title":"Invoke - Stopping the Development Environment","text":"<p>The last command to know for now is <code>invoke stop</code>.</p> <pre><code>\u279c invoke stop\nStopping Nautobot...\nRunning docker-compose command \"down\"\nStopping nautobot_app_vpn_worker_1   ...\nStopping nautobot_app_vpn_nautobot_1 ...\nStopping nautobot_app_vpn_docs_1     ...\nStopping nautobot_app_vpn_redis_1    ...\nStopping nautobot_app_vpn_postgres_1 ...\nStopping nautobot_app_vpn_worker_1   ... done\nStopping nautobot_app_vpn_nautobot_1 ... done\nStopping nautobot_app_vpn_postgres_1 ... done\nStopping nautobot_app_vpn_redis_1    ... done\nStopping nautobot_app_vpn_docs_1     ... done\nRemoving nautobot_app_vpn_worker_1   ...\nRemoving nautobot_app_vpn_nautobot_1 ...\nRemoving nautobot_app_vpn_docs_1     ...\nRemoving nautobot_app_vpn_redis_1    ...\nRemoving nautobot_app_vpn_postgres_1 ...\nRemoving nautobot_app_vpn_postgres_1 ... done\nRemoving nautobot_app_vpn_docs_1     ... done\nRemoving nautobot_app_vpn_worker_1   ... done\nRemoving nautobot_app_vpn_redis_1    ... done\nRemoving nautobot_app_vpn_nautobot_1 ... done\nRemoving network nautobot_app_vpn_default\n</code></pre> <p>This will safely shut down all of your running Docker containers for this project. When you are ready to spin containers back up, it is as simple as running <code>invoke start</code> again as seen previously.</p> <p>Warning</p> <p>If you're wanting to reset the database and configuration settings, you can use the <code>invoke destroy</code> command, but you will lose any data stored in those containers, so make sure that is what you want to do.</p>"},{"location":"dev/dev_environment/#real-time-updates-how-cool","title":"Real-Time Updates? How Cool!","text":"<p>Your environment should now be fully setup, all necessary Docker containers are created and running, and you're logged into Nautobot in your web browser. Now what?</p> <p>Now you can start developing your app in the project folder!</p> <p>The magic here is the root directory is mounted inside your Docker containers when built and ran, so any changes made to the files in here are directly updated to the Nautobot app code running in Docker. This means that as you modify the code in your app folder, the changes will be instantly updated in Nautobot.</p> <p>Warning</p> <p>There are a few exceptions to this, as outlined in the section To Rebuild or Not To Rebuild.</p> <p>The back-end Django process is setup to automatically reload itself (it only takes a couple of seconds) every time a file is updated (saved). So for example, if you were to update one of the files like <code>tables.py</code>, then save it, the changes will be visible right away in the web browser!</p> <p>Note</p> <p>You may get connection refused while Django reloads, but it should be refreshed fairly quickly.</p>"},{"location":"dev/dev_environment/#docker-logs","title":"Docker Logs","text":"<p>When trying to debug an issue, one helpful thing you can look at are the logs within the Docker containers.</p> <pre><code>\u279c docker logs &lt;name of container&gt; -f\n</code></pre> <p>Note</p> <p>The <code>-f</code> tag will keep the logs open, and output them in realtime as they are generated.</p> <p>Info</p> <p>Want to limit the log output even further? Use the <code>--tail &lt;#&gt;</code> command line argument in conjunction with <code>-f</code>.</p> <p>So for example, our app is named <code>nautobot_app_vpn</code>, the command would most likely be <code>docker logs nautobot_app_vpn_nautobot_1 -f</code>. You can find the name of all running containers via <code>docker ps</code>.</p> <p>If you want to view the logs specific to the worker container, simply use the name of that container instead.</p>"},{"location":"dev/dev_environment/#to-rebuild-or-not-to-rebuild","title":"To Rebuild or Not to Rebuild","text":"<p>Most of the time, you will not need to rebuild your images. Simply running <code>invoke start</code> and <code>invoke stop</code> is enough to keep your environment going.</p> <p>However there are a couple of instances when you will want to.</p>"},{"location":"dev/dev_environment/#updating-environment-variables","title":"Updating Environment Variables","text":"<p>To add environment variables to your containers, thus allowing Nautobot to use them, you will update/add them in the <code>development/development.env</code> file. However, doing so is considered updating the underlying container shell, instead of Django (which auto restarts itself on changes).</p> <p>To get new environment variables to take effect, you will need stop any running images, rebuild the images, then restart them. This can easily be done with 3 commands:</p> <pre><code>\u279c invoke stop\n\u279c invoke build\n\u279c invoke start\n</code></pre> <p>Once completed, the new/updated environment variables should now be live.</p>"},{"location":"dev/dev_environment/#installing-additional-python-packages","title":"Installing Additional Python Packages","text":"<p>If you want your app to leverage another available Nautobot app or another Python package, you can easily add them into your Docker environment.</p> <pre><code>\u279c poetry shell\n\u279c poetry add &lt;package_name&gt;\n</code></pre> <p>Once the dependencies are resolved, stop the existing containers, rebuild the Docker image, and then start all containers again.</p> <pre><code>\u279c invoke stop\n\u279c invoke build\n\u279c invoke start\n</code></pre>"},{"location":"dev/dev_environment/#installing-additional-nautobot-apps","title":"Installing Additional Nautobot Apps","text":"<p>Let's say for example you want the new app you're creating to integrate into Slack. To do this, you will want to integrate into the existing Nautobot ChatOps App.</p> <pre><code>\u279c poetry shell\n\u279c poetry add nautobot-chatops\n</code></pre> <p>Once you activate the virtual environment via Poetry, you then tell Poetry to install the new app.</p> <p>Before you continue, you'll need to update the file <code>development/nautobot_config.py</code> accordingly with the name of the new app under <code>PLUGINS</code> and any relevant settings as necessary for the app under <code>PLUGINS_CONFIG</code>. Since you're modifying the underlying OS (not just Django files), you need to rebuild the image. This is a similar process to updating environment variables, which was explained earlier.</p> <pre><code>\u279c invoke stop\n\u279c invoke build\n\u279c invoke start\n</code></pre> <p>Once the containers are up and running, you should now see the new app installed in your Nautobot instance.</p> <p>Note</p> <p>You can even launch an <code>ngrok</code> service locally on your laptop, pointing to port 8080 (such as for chatops development), and it will point traffic directly to your Docker images.</p>"},{"location":"dev/dev_environment/#updating-python-version","title":"Updating Python Version","text":"<p>To update the Python version, you can update it within <code>tasks.py</code>.</p> <pre><code>namespace = Collection(\"nautobot_app_vpn\")\nnamespace.configure(\n    {\n        \"nautobot_app_vpn\": {\n            ...\n            \"python_ver\": \"3.11\",\n        ...\n        }\n    }\n)\n</code></pre> <p>Or set the <code>INVOKE_NAUTOBOT_APP_VPN_PYTHON_VER</code> variable.</p>"},{"location":"dev/dev_environment/#updating-nautobot-version","title":"Updating Nautobot Version","text":"<p>To update the Nautobot version, you can update it within <code>tasks.py</code>.</p> <pre><code>namespace = Collection(\"nautobot_app_vpn\")\nnamespace.configure(\n    {\n        \"nautobot_app_vpn\": {\n            ...\n            \"nautobot_ver\": \"2.0.0\",\n        ...\n        }\n    }\n)\n</code></pre> <p>Or set the <code>INVOKE_NAUTOBOT_APP_VPN_NAUTOBOT_VER</code> variable.</p>"},{"location":"dev/dev_environment/#other-miscellaneous-commands-to-know","title":"Other Miscellaneous Commands To Know","text":""},{"location":"dev/dev_environment/#python-shell","title":"Python Shell","text":"<p>To drop into a Django shell for Nautobot (in the Docker container) run:</p> <pre><code>\u279c invoke nbshell\n</code></pre> <p>This is the same as running:</p> <pre><code>\u279c invoke cli\n\u279c nautobot-server nbshell\n</code></pre>"},{"location":"dev/dev_environment/#ipython-shell-plus","title":"iPython Shell Plus","text":"<p>Django also has a more advanced shell that uses iPython and that will automatically import all the models:</p> <pre><code>\u279c invoke shell-plus\n</code></pre> <p>This is the same as running:</p> <pre><code>\u279c invoke cli\n\u279c nautobot-server shell_plus\n</code></pre>"},{"location":"dev/dev_environment/#tests","title":"Tests","text":"<p>To run tests against your code, you can run all of the tests that the CI runs against any new PR with:</p> <pre><code>\u279c invoke tests\n</code></pre> <p>To run an individual test, you can run any or all of the following:</p> <pre><code>\u279c invoke unittest\n\u279c invoke ruff\n\u279c invoke pylint\n</code></pre>"},{"location":"dev/dev_environment/#app-configuration-schema","title":"App Configuration Schema","text":"<p>In the package source, there is the <code>nautobot_app_vpn/app-config-schema.json</code> file, conforming to the JSON Schema format. This file is used to validate the configuration of the app in CI pipelines.</p> <p>If you make changes to <code>PLUGINS_CONFIG</code> or the configuration schema, you can run the following command to validate the schema:</p> <pre><code>invoke validate-app-config\n</code></pre> <p>To generate the <code>app-config-schema.json</code> file based on the current <code>PLUGINS_CONFIG</code> configuration, run the following command:</p> <pre><code>invoke generate-app-config-schema\n</code></pre> <p>This command can only guess the schema, so it's up to the developer to manually update the schema as needed.</p>"},{"location":"dev/extending/","title":"Extending the App","text":"<p>Developer Note - Remove Me!</p> <p>Information on how to extend the App functionality.</p> <p>Extending the application is welcome, however it is best to open an issue first, to ensure that a PR would be accepted and makes sense in terms of features and design.</p>"},{"location":"dev/release_checklist/","title":"Release Checklist","text":"<p>This document is intended for app maintainers and outlines the steps to perform when releasing a new version of the app.</p> <p>Important</p> <p>Before starting, make sure your local <code>develop</code>, <code>main</code>, and (if applicable) the current LTM branch are all up to date with upstream!</p> <pre><code>git fetch\ngit switch develop &amp;&amp; git pull # and repeat for main/ltm\n</code></pre> <p>Choose your own adventure:</p> <ul> <li>LTM release? Jump here.</li> <li>Patch release from <code>develop</code>? Jump here.</li> <li>Minor release? Continue with Minor Version Bumps and then All Releases from <code>develop</code>.</li> </ul>"},{"location":"dev/release_checklist/#minor-version-bumps","title":"Minor Version Bumps","text":""},{"location":"dev/release_checklist/#update-requirements","title":"Update Requirements","text":"<p>Every minor version release should refresh <code>poetry.lock</code>, so that it lists the most recent stable release of each package. To do this:</p> <ol> <li>Run <code>poetry update --dry-run</code> to have Poetry automatically tell you what package updates are available and the versions it would upgrade to. This requires an existing environment created from the lock file (i.e. via <code>poetry install</code>).</li> <li>Review each requirement's release notes for any breaking or otherwise noteworthy changes.</li> <li>Run <code>poetry update &lt;package&gt;</code> to update the package versions in <code>poetry.lock</code> as appropriate.</li> <li>If a required package requires updating to a new release not covered in the version constraints for a package as defined in <code>pyproject.toml</code>, (e.g. <code>Django ~3.1.7</code> would never install <code>Django &gt;=4.0.0</code>), update it manually in <code>pyproject.toml</code>.</li> <li>Run <code>poetry install</code> to install the refreshed versions of all required packages.</li> <li>Run all tests (<code>poetry run invoke tests</code>) and check that the UI and API function as expected.</li> </ol>"},{"location":"dev/release_checklist/#update-documentation","title":"Update Documentation","text":"<p>If there are any changes to the compatibility matrix (such as a bump in the minimum supported Nautobot version), update it accordingly.</p> <p>Commit any resulting changes from the following sections to the documentation before proceeding with the release.</p> <p>Tip</p> <p>Fire up the documentation server in your development environment with <code>poetry run mkdocs serve</code>! This allows you to view the documentation site locally (the link is in the output of the command) and automatically rebuilds it as you make changes.</p>"},{"location":"dev/release_checklist/#verify-the-installation-and-upgrade-steps","title":"Verify the Installation and Upgrade Steps","text":"<p>Follow the installation instructions to perform a new production installation of the app. If possible, also test the upgrade process from the previous released version.</p> <p>The goal of this step is to walk through the entire install process as documented to make sure nothing there needs to be changed or updated, to catch any errors or omissions in the documentation, and to ensure that it is current with each release.</p>"},{"location":"dev/release_checklist/#all-releases-from-develop","title":"All Releases from <code>develop</code>","text":""},{"location":"dev/release_checklist/#verify-ci-build-status","title":"Verify CI Build Status","text":"<p>Ensure that continuous integration testing on the <code>develop</code> branch is completing successfully.</p>"},{"location":"dev/release_checklist/#bump-the-version","title":"Bump the Version","text":"<p>Update the package version using <code>poetry version</code> if necessary. This command shows the current version of the project or bumps the version of the project and writes the new version back to <code>pyproject.toml</code> if a valid bump rule is provided.</p> <p>The new version must be a valid semver string or a valid bump rule: <code>patch</code>, <code>minor</code>, <code>major</code>, <code>prepatch</code>, <code>preminor</code>, <code>premajor</code>, <code>prerelease</code>. Always try to use a bump rule when you can.</p> <p>Display the current version with no arguments:</p> <pre><code>&gt; poetry version\nnautobot_app_vpn 1.0.0-beta.2\n</code></pre> <p>Bump pre-release versions using <code>prerelease</code>:</p> <pre><code>&gt; poetry version prerelease\nBumping version from 1.0.0-beta.2 to 1.0.0-beta.3\n</code></pre> <p>For major versions, use <code>major</code>:</p> <pre><code>&gt; poetry version major\nBumping version from 1.0.0-beta.2 to 1.0.0\n</code></pre> <p>For patch versions, use <code>minor</code>:</p> <pre><code>&gt; poetry version minor\nBumping version from 1.0.0 to 1.1.0\n</code></pre> <p>And lastly, for patch versions, you guessed it, use <code>patch</code>:</p> <pre><code>&gt; poetry version patch\nBumping version from 1.1.0 to 1.1.1\n</code></pre> <p>Please see the official Poetry documentation on <code>version</code> for more information.</p>"},{"location":"dev/release_checklist/#update-the-changelog","title":"Update the Changelog","text":"<p>Important</p> <p>The changelog must adhere to the Keep a Changelog style guide.</p> <p>This guide uses <code>1.4.2</code> as the new version in its examples, so change it to match the version you bumped to in the previous step! Every. single. time. you. copy/paste commands :)</p> <p>First, create a release branch off of <code>develop</code> (<code>git switch -c release-1.4.2 develop</code>).</p> <p>You will need to have the project's poetry environment built at this stage, as the towncrier command runs locally only. If you don't have it, run <code>poetry install</code> first.</p> <p>Generate release notes with <code>invoke generate-release-notes --version 1.4.2</code> and answer <code>yes</code> to the prompt <code>Is it okay if I remove those files? [Y/n]:</code>. This will update the release notes in <code>docs/admin/release_notes/version_X.Y.md</code>, stage that file in git, and <code>git rm</code> all the fragments that have now been incorporated into the release notes.</p> <p>There are two possibilities:</p> <ol> <li>If you're releasing a new major or minor version, rename the <code>version_X.Y.md</code> file accordingly (e.g. rename to <code>docs/admin/release_notes/version_1.4.md</code>). Update the <code>Release Overview</code> and add this new page to the table of contents within <code>mkdocs.yml</code>.</li> <li>If you're releasing a patch version, copy your version's section from the <code>version_X.Y.md</code> file into the already existing <code>docs/admin/release_notes/version_1.4.md</code> file. Delete the <code>version_X.Y.md</code> file.</li> </ol> <p>Stage all the changes (<code>git add</code>) and check the diffs to verify all of the changes are correct (<code>git diff --cached</code>).</p> <p>Commit <code>git commit -m \"Release v1.4.2\"</code> and <code>git push</code> the staged changes.</p>"},{"location":"dev/release_checklist/#submit-release-pull-request","title":"Submit Release Pull Request","text":"<p>Submit a pull request titled <code>Release v1.4.2</code> to merge your release branch into <code>main</code>. Copy the documented release notes into the pull request's body.</p> <p>Important</p> <p>Do not squash merge this branch into <code>main</code>. Make sure to select <code>Create a merge commit</code> when merging in GitHub.</p> <p>Once CI has completed on the PR, merge it.</p>"},{"location":"dev/release_checklist/#create-a-new-release-in-github","title":"Create a New Release in GitHub","text":"<p>Draft a new release with the following parameters.</p> <ul> <li>Tag: Input current version (e.g. <code>v1.4.2</code>) and select <code>Create new tag: v1.4.2 on publish</code></li> <li>Target: <code>main</code></li> <li>Title: Version and date (e.g. <code>v1.4.2 - 2024-04-02</code>)</li> </ul> <p>Click \"Generate Release Notes\" and edit the auto-generated content as follows:</p> <ul> <li>Change the entries generated by GitHub to only the usernames of the contributors. e.g. <code>* Updated dockerfile by @nautobot_user in https://git.noc.issworld.com/narendra.polisetty/nautobot-app-vpn/pull/123</code> -&gt; <code>* @nautobot_user</code>.<ul> <li>This should give you the list for the new <code>Contributors</code> section.</li> <li>Make sure there are no duplicated entries.</li> </ul> </li> <li>Replace the content of the <code>What's Changed</code> section with the description of changes from the release PR (what towncrier generated).</li> <li>If it exists, leave the <code>New Contributors</code> list as it is.</li> </ul> <p>The release notes should look as follows:</p> <pre><code>## What's Changed\n\n**Towncrier generated Changed/Fixed/Housekeeping etc. sections here**\n\n## Contributors\n\n* @alice\n* @bob\n\n## New Contributors\n\n* @bob\n\n**Full Changelog**: https://git.noc.issworld.com/narendra.polisetty/nautobot-app-vpn/compare/v1.4.1...v1.4.2\n</code></pre> <p>Publish the release!</p>"},{"location":"dev/release_checklist/#create-a-pr-from-main-back-to-develop","title":"Create a PR from <code>main</code> back to <code>develop</code>","text":"<p>First, sync your <code>main</code> branch with upstream changes: <code>git switch main &amp;&amp; git pull</code>.</p> <p>Create a new branch from <code>main</code> called <code>release-1.4.2-to-develop</code> and use <code>poetry version prepatch</code> to bump the development version to the next release.</p> <p>For example, if you just released <code>v1.4.2</code>:</p> <pre><code>&gt; git switch -c release-1.4.2-to-develop main\nSwitched to a new branch 'release-1.4.2-to-develop'\n\n&gt; poetry version prepatch\nBumping version from 1.4.2 to 1.4.3a1\n\n&gt; git add pyproject.toml &amp;&amp; git commit -m \"Bump version\"\n\n&gt; git push\n</code></pre> <p>Important</p> <p>Do not squash merge this branch into <code>develop</code>. Make sure to select <code>Create a merge commit</code> when merging in GitHub.</p> <p>Open a new PR from <code>release-1.4.2-to-develop</code> against <code>develop</code>, wait for CI to pass, and merge it.</p>"},{"location":"dev/release_checklist/#final-checks","title":"Final checks","text":"<p>At this stage, the CI should be running or finished for the <code>v1.4.2</code> tag and a package successfully published to PyPI and added into the GitHub Release. Double check that's the case.</p> <p>Documentation should also have been built for the tag on ReadTheDocs and if you're reading this page online, refresh it and look for the new version in the little version fly-out menu down at the bottom right of the page.</p> <p>All done!</p>"},{"location":"dev/release_checklist/#ltm-releases","title":"LTM Releases","text":"<p>For projects maintaining a Nautobot LTM compatible release, all development and release management is done through the <code>ltm-x.y</code> branch. The <code>x.y</code> relates to the LTM version of Nautobot it's compatible with, for example <code>1.6</code>.</p> <p>The process is similar to releasing from <code>develop</code>, but there is no need for post-release branch syncing because you'll release directly from the LTM branch:</p> <ol> <li>Make sure your <code>ltm-1.6</code> branch is passing CI.</li> <li>Create a release branch from the <code>ltm-1.6</code> branch: <code>git switch -c release-1.2.3 ltm-1.6</code>.</li> <li>Bump up the patch version <code>poetry version patch</code>. If you're backporting a feature instead of bugfixes, bump the minor version instead with <code>poetry version minor</code>.</li> <li>Generate the release notes: <code>invoke generate-release-notes --version 1.2.3</code>.</li> <li>Move the release notes from the generated <code>docs/admin/release_notes/version_X.Y.md</code> to <code>docs/admin/release_notes/version_1.2.md</code>.</li> <li>Add all the changes and <code>git commit -m \"Release v1.2.3\"</code>, then <code>git push</code>.</li> <li>Open a new PR against <code>ltm-1.6</code>. Once CI is passing in the PR, <code>Create a merge commit</code> (don't squash!).</li> <li>Create a New Release in GitHub - use the same steps documented here.</li> <li>Open a separate PR against <code>develop</code> to synchronize all LTM release changelogs into the latest version of the docs for visibility.</li> </ol>"},{"location":"dev/code_reference/","title":"Code Reference","text":"<p>Auto-generated code reference documentation from docstrings.</p> <p>Developer Note - Remove Me!</p> <p>Uses mkdocstrings syntax to auto-generate code documentation from docstrings. Two example pages are provided (api and package), add new stubs for each module or package that you think has relevant documentation.</p>"},{"location":"dev/code_reference/api/","title":"VPN APP API Package","text":""},{"location":"dev/code_reference/api/#nautobot_app_vpn.api","title":"<code>nautobot_app_vpn.api</code>","text":"<p>Initialize the Nautobot VPN plugin API package.</p>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.IPSECTunnelViewSet","title":"<code>IPSECTunnelViewSet</code>","text":"<p>               Bases: <code>ModelViewSet</code></p> <p>API viewset for IPSec Tunnels.</p> Source code in <code>nautobot_app_vpn/api/viewsets.py</code> <pre><code>class IPSECTunnelViewSet(viewsets.ModelViewSet):\n    \"\"\"API viewset for IPSec Tunnels.\"\"\"\n\n    # &lt;&lt;&lt; UPDATED queryset: Removed bind_interface from select_related &gt;&gt;&gt;\n    queryset = (\n        IPSECTunnel.objects.select_related(\n            \"ike_gateway\",\n            \"ipsec_crypto_profile\",\n            \"status\",\n            \"tunnel_interface\",\n            \"monitor_profile\",\n        )\n        .prefetch_related(\n            \"devices\",\n            \"proxy_ids\",\n        )\n        .order_by(\"name\")\n        .distinct()\n    )\n\n    serializer_class = IPSECTunnelSerializer\n    permission_classes = [IsAdminOrReadOnly]\n    filter_backends = [DjangoFilterBackend, filters.OrderingFilter, filters.SearchFilter]\n    filterset_class = IPSECTunnelFilterSet\n\n    ordering_fields = [\n        \"name\",\n        \"ike_gateway__name\",\n        \"ipsec_crypto_profile__name\",\n        \"tunnel_interface__name\",\n        \"status__name\",\n        \"enable_tunnel_monitor\",\n        \"monitor_destination_ip\",\n    ]\n    search_fields = [\n        \"name\",\n        \"description\",\n        \"ike_gateway__name\",\n        \"ipsec_crypto_profile__name\",\n        \"tunnel_interface__name\",\n        \"monitor_destination_ip\",\n    ]\n    pagination_class = StandardResultsSetPagination\n\n    def perform_create(self, serializer):\n        serializer.save()\n\n    def perform_update(self, serializer):\n        serializer.save()\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.IsAdminOrReadOnly","title":"<code>IsAdminOrReadOnly</code>","text":"<p>               Bases: <code>BasePermission</code></p> <p>Allow only staff/superusers to modify data. Read-only access is allowed for everyone.</p> Source code in <code>nautobot_app_vpn/api/permissions.py</code> <pre><code>class IsAdminOrReadOnly(BasePermission):\n    \"\"\"Allow only staff/superusers to modify data.\n    Read-only access is allowed for everyone.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        if request.method in SAFE_METHODS:\n            return True\n        return request.user and (request.user.is_staff or request.user.is_superuser)\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.StandardResultsSetPagination","title":"<code>StandardResultsSetPagination</code>","text":"<p>               Bases: <code>PageNumberPagination</code></p> <p>Standard pagination for API endpoints.</p> <ul> <li>Supports dynamic page sizes via <code>?page_size=X</code></li> <li>Prevents excessive page loads with <code>max_page_size=100</code></li> <li>Defaults to 25 results per page   for a better balance of performance and usability.</li> </ul> Source code in <code>nautobot_app_vpn/api/pagination.py</code> <pre><code>class StandardResultsSetPagination(PageNumberPagination):\n    \"\"\"Standard pagination for API endpoints.\n\n    - Supports dynamic page sizes via `?page_size=X`\n    - Prevents excessive page loads with `max_page_size=100`\n    - Defaults to 25 results per page\n      for a better balance of performance and usability.\n    \"\"\"\n\n    page_size = 25\n    page_size_query_param = \"page_size\"\n    max_page_size = 200\n    last_page_strings = (\"last\",)\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.TunnelMonitorProfileSerializer","title":"<code>TunnelMonitorProfileSerializer</code>","text":"<p>               Bases: <code>BaseModelSerializer</code></p> <p>Serializer for Tunnel Monitor Profiles.</p> Source code in <code>nautobot_app_vpn/api/serializers.py</code> <pre><code>class TunnelMonitorProfileSerializer(BaseModelSerializer):\n    \"\"\"Serializer for Tunnel Monitor Profiles.\"\"\"\n\n    url = serializers.HyperlinkedIdentityField(view_name=\"plugins-api:nautobot_app_vpn-api:tunnelmonitorprofile-detail\")\n    action = ChoiceField(choices=TunnelMonitorActionChoices.choices, required=False)\n\n    class Meta:\n        model = TunnelMonitorProfile\n        fields = [\"id\", \"display\", \"url\", \"name\", \"action\", \"interval\", \"threshold\", \"created\", \"last_updated\"]\n        read_only_fields = [\"id\", \"display\", \"url\", \"created\", \"last_updated\"]\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.TunnelMonitorProfileViewSet","title":"<code>TunnelMonitorProfileViewSet</code>","text":"<p>               Bases: <code>ModelViewSet</code></p> <p>API viewset for Tunnel Monitor Profiles.</p> Source code in <code>nautobot_app_vpn/api/viewsets.py</code> <pre><code>class TunnelMonitorProfileViewSet(viewsets.ModelViewSet):\n    \"\"\"API viewset for Tunnel Monitor Profiles.\"\"\"\n\n    queryset = TunnelMonitorProfile.objects.all().order_by(\"name\")\n    serializer_class = TunnelMonitorProfileSerializer\n    permission_classes = [IsAdminOrReadOnly]\n    filter_backends = [DjangoFilterBackend, filters.OrderingFilter, filters.SearchFilter]  # Uncommented filter_backends\n    filterset_class = TunnelMonitorProfileFilterSet\n    ordering_fields = [\"name\", \"action\", \"interval\", \"threshold\"]\n    search_fields = [\"name\"]\n    pagination_class = StandardResultsSetPagination\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.VPNTopologyFilterOptionsView","title":"<code>VPNTopologyFilterOptionsView</code>","text":"<p>               Bases: <code>APIView</code></p> <p>API view to return distinct filter options for countries, platforms, roles, etc., primarily based on data currently associated with IPSECTunnels in Nautobot's relational DB.</p> Source code in <code>nautobot_app_vpn/api/viewsets.py</code> <pre><code>class VPNTopologyFilterOptionsView(APIView):\n    \"\"\"API view to return distinct filter options for countries, platforms, roles, etc.,\n    primarily based on data currently associated with IPSECTunnels in Nautobot's relational DB.\n    \"\"\"\n\n    permission_classes = [IsAuthenticated]\n\n    def _get_device_country_from_name(self, device_name):\n        \"\"\"Derives country from device name based on 'CODE-...' convention.\"\"\"\n        if device_name:\n            parts = device_name.split(\"-\")\n            if parts:\n                return parts[0].upper()\n        return None\n\n    def get(self, request):\n        logger.debug(f\"Filter options GET request from user {request.user}\")\n        countries = set()\n        ike_versions = set()\n        statuses = set()\n        tunnel_roles = set()\n        devices_map = {}\n        locations = set()\n        platforms_set = set()  # store (id, name)\n\n        tunnels_qs = IPSECTunnel.objects.select_related(\n            \"ike_gateway\", \"status\", \"ike_gateway__local_platform\", \"ike_gateway__peer_platform\"\n        ).prefetch_related(\n            \"ike_gateway__local_devices__platform\",\n            \"ike_gateway__local_devices__location\",\n            \"ike_gateway__local_devices__role\",\n            \"ike_gateway__peer_devices__platform\",\n            \"ike_gateway__peer_devices__location\",\n            \"ike_gateway__peer_devices__role\",\n        )\n\n        for tunnel in tunnels_qs:\n            if tunnel.status and tunnel.status.name:\n                statuses.add(tunnel.status.name)\n            if tunnel.role:\n                tunnel_roles.add(str(tunnel.role))\n            gw = tunnel.ike_gateway\n            if gw:\n                if gw.ike_version:\n                    ike_versions.add(str(gw.ike_version))\n\n                for plat in [gw.local_platform, gw.peer_platform]:\n                    if plat:\n                        platforms_set.add((plat.id, plat.name))\n\n                for dev_group in [gw.local_devices.all(), gw.peer_devices.all()]:\n                    for dev in dev_group:\n                        if dev and dev.name:\n                            devices_map[str(dev.pk)] = dev.name\n                            country = self._get_device_country_from_name(dev.name)\n                            if country:\n                                countries.add(country)\n                        if dev and dev.location and dev.location.name:\n                            locations.add(dev.location.name)\n                        if dev and dev.platform:\n                            platforms_set.add((dev.platform.id, dev.platform.name))\n\n        all_defined_platforms = Platform.objects.all().values(\"id\", \"name\").distinct()\n        for plat in all_defined_platforms:\n            platforms_set.add((plat[\"id\"], plat[\"name\"]))\n\n        platforms_out = [\n            {\"id\": pid, \"name\": n} for pid, n in sorted(platforms_set, key=lambda x: (x[1] or \"\", x[0] or \"\")) if n\n        ]\n\n        return Response(\n            {\n                \"countries\": sorted(filter(None, countries)),\n                \"ike_versions\": sorted(filter(None, ike_versions)),\n                \"statuses\": sorted(filter(None, statuses)),\n                \"roles\": sorted(filter(None, tunnel_roles)),\n                \"tunnel_roles\": sorted(filter(None, tunnel_roles)),\n                \"devices\": [\n                    {\"id\": pk, \"label\": name} for pk, name in sorted(devices_map.items(), key=lambda item: item[1])\n                ],\n                \"locations\": sorted(filter(None, locations)),\n                \"platforms\": platforms_out,\n            }\n        )\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.VPNTopologyNeo4jView","title":"<code>VPNTopologyNeo4jView</code>","text":"<p>               Bases: <code>APIView</code></p> <p>API view to return VPN topology nodes and edges for visualization, sourced from Neo4j, with support for filtering.</p> Source code in <code>nautobot_app_vpn/api/viewsets.py</code> <pre><code>class VPNTopologyNeo4jView(APIView):\n    \"\"\"API view to return VPN topology nodes and edges for visualization,\n    sourced from Neo4j, with support for filtering.\n    \"\"\"\n\n    permission_classes = [IsAuthenticated]\n\n    def _build_cypher_queries_and_params(self, filters_dict):\n        \"\"\"Builds Cypher queries and parameters for fetching nodes and edges based on request filters.\n        Returns: (nodes_query_string, edges_query_string, query_parameters_dict)\n        \"\"\"\n        query_params = {}\n\n        node_match_clause = \"MATCH (n:VPNNode)\"\n        node_where_clauses = []\n\n        if filters_dict.get(\"country\"):\n            node_where_clauses.append(\"toLower(n.country) = toLower($country)\")\n            query_params[\"country\"] = filters_dict[\"country\"]\n\n        if filters_dict.get(\"platform\"):\n            platform_val = filters_dict[\"platform\"]\n            node_where_clauses.append(\"toLower(n.platform_name) CONTAINS toLower($platform)\")\n            query_params[\"platform\"] = platform_val\n\n        if filters_dict.get(\"location\"):\n            node_where_clauses.append(\"toLower(n.location_name) CONTAINS toLower($location)\")\n            query_params[\"location\"] = filters_dict[\"location\"]\n\n        if filters_dict.get(\"device\"):\n            val = str(filters_dict[\"device\"]).strip()\n            node_where_clauses.append(\n                \"(\"\n                \"toLower($device_name) IN [dev IN n.device_names | toLower(dev)] \"\n                \"OR $device_name IN n.nautobot_device_pks \"\n                \"OR toLower(n.label) CONTAINS toLower($device_name)\"\n                \")\"\n            )\n            query_params[\"device_name\"] = val\n\n        if filters_dict.get(\"role\"):\n            node_where_clauses.append(\"toLower(n.role) = toLower($device_role)\")\n            query_params[\"device_role\"] = filters_dict[\"role\"]\n\n        nodes_query_string = node_match_clause\n        if node_where_clauses:\n            nodes_query_string += \" WHERE \" + \" AND \".join(node_where_clauses)\n        nodes_query_string += \" RETURN n\"\n\n        edges_query_string = (\n            \"MATCH (n1:VPNNode)-[r:TUNNEL]-&gt;(n2:VPNNode) WHERE n1.id IN $node_ids AND n2.id IN $node_ids\"\n        )\n        edge_filter_conditions = []\n\n        if filters_dict.get(\"status\"):\n            edge_filter_conditions.append(\"toLower(r.status) = toLower($tunnel_status)\")\n            query_params[\"tunnel_status\"] = filters_dict[\"status\"]\n\n        if filters_dict.get(\"ike_version\"):\n            edge_filter_conditions.append(\"toLower(r.ike_version) = toLower($ike_version)\")\n            query_params[\"ike_version\"] = filters_dict[\"ike_version\"]\n\n        if filters_dict.get(\"role\"):  # Use \"role\" consistently\n            edge_filter_conditions.append(\"toLower(r.role) = toLower($tunnel_role)\")\n            query_params[\"tunnel_role\"] = filters_dict[\"role\"]\n\n        if edge_filter_conditions:\n            edges_query_string += \" AND \" + \" AND \".join(edge_filter_conditions)\n\n        edges_query_string += \" RETURN n1.id AS source, n2.id AS target, r AS properties\"\n\n        return nodes_query_string, edges_query_string, query_params\n\n    def get(self, request):\n        logger.info(f\"Neo4j VPN Topology GET request from user {request.user} with filters: {request.GET.dict()}\")\n\n        if not all(hasattr(settings, attr) for attr in [\"NEO4J_URI\", \"NEO4J_USER\", \"NEO4J_PASSWORD\"]):\n            logger.error(\"Neo4j connection settings are not fully configured in Nautobot settings.\")\n            return Response({\"error\": \"Graph database service is not configured.\"}, status=503)\n\n        driver = None\n        try:\n            driver = GraphDatabase.driver(settings.NEO4J_URI, auth=(settings.NEO4J_USER, settings.NEO4J_PASSWORD))\n            driver.verify_connectivity()\n        except Exception as e:\n            logger.error(f\"Failed to connect to Neo4j for topology view: {e}\", exc_info=True)\n            return Response({\"error\": \"Could not connect to graph database.\"}, status=503)\n\n        formatted_nodes = []\n        formatted_edges = []\n\n        request_filters = request.GET.dict()\n        nodes_cypher, edges_cypher, query_params_base = self._build_cypher_queries_and_params(request_filters)\n\n        try:\n            with driver.session(database=getattr(settings, \"NEO4J_DATABASE\", \"neo4j\")) as session:\n                logger.debug(f\"Executing Neo4j Node Query: {nodes_cypher} with params: {query_params_base}\")\n                node_records = session.run(nodes_cypher, query_params_base)\n                focus_node_ids = set()\n                temp_nodes_dict = {}\n\n                for record in node_records:\n                    node_data_neo = record[\"n\"]\n                    node_properties = dict(node_data_neo)\n                    node_id = node_properties.get(\"id\")\n                    if node_id:\n                        focus_node_ids.add(node_id)\n                        if node_id not in temp_nodes_dict:\n                            lat = node_properties.get(\"latitude\")\n                            lon = node_properties.get(\"longitude\")\n                            x = node_properties.get(\"x\")\n                            y = node_properties.get(\"y\")\n                            pos = None\n\n                            if x is not None and y is not None:\n                                try:\n                                    pos = {\"x\": float(x), \"y\": float(y)}\n                                except Exception:\n                                    pos = None\n                            elif lat is not None and lon is not None:\n                                try:\n                                    x_map, y_map = latlon_to_xy(float(lat), float(lon), svg_width=2754, svg_height=1398)\n                                    pos = {\"x\": x_map, \"y\": y_map}\n                                except Exception:\n                                    pos = {\"x\": random.uniform(-100, 100), \"y\": random.uniform(-100, 100)}\n                            else:\n                                pos = {\"x\": random.uniform(-100, 100), \"y\": random.uniform(-100, 100)}\n\n                            node_obj = {\n                                \"data\": {\n                                    **node_properties,\n                                    \"is_ha_pair\": node_properties.get(\"is_ha_pair\", False),\n                                    \"node_type\": node_properties.get(\"node_type\", \"DeviceGroup\"),\n                                    \"label\": node_properties.get(\"label\", \"\"),\n                                }\n                            }\n                            if pos:\n                                node_obj[\"position\"] = pos\n                            temp_nodes_dict[node_id] = node_obj\n\n                if focus_node_ids:\n                    edge_query = \"\"\"\n                        MATCH (n1:VPNNode)-[r:TUNNEL]-&gt;(n2:VPNNode)\n                        WHERE n1.id IN $focus_node_ids OR n2.id IN $focus_node_ids\n                        RETURN n1.id AS source, n2.id AS target, r AS properties\n                    \"\"\"\n                    logger.debug(f\"Executing Neo4j Edge Query: {edge_query} with focus_node_ids: {focus_node_ids}\")\n                    edge_records = session.run(edge_query, {\"focus_node_ids\": list(focus_node_ids)})\n\n                    all_node_ids = set(focus_node_ids)  # Start with focus nodes\n\n                    for record in edge_records:\n                        source_id = record[\"source\"]\n                        target_id = record[\"target\"]\n                        all_node_ids.add(source_id)\n                        all_node_ids.add(target_id)\n\n                        edge_rel_properties = dict(record[\"properties\"])\n                        if \"nautobot_tunnel_pk\" in edge_rel_properties:\n                            edge_rel_properties[\"id\"] = f\"tunnel_{edge_rel_properties['nautobot_tunnel_pk']}\"\n                        else:\n                            edge_rel_properties[\"id\"] = f\"edge_{record['properties'].element_id}\"\n\n                        edge_rel_properties[\"tooltip_details\"] = {\n                            \"Tunnel Name\": edge_rel_properties.get(\"name\", \"N/A\"),\n                            \"Status\": edge_rel_properties.get(\"status\", \"N/A\"),\n                            \"Role\": edge_rel_properties.get(\"role\", \"N/A\"),\n                            \"IKE Gateway\": edge_rel_properties.get(\"ike_gateway_name\", \"N/A\"),\n                            \"IKE Version\": edge_rel_properties.get(\"ike_version\", \"N/A\"),\n                            \"IPsec Profile\": edge_rel_properties.get(\"ipsec_profile_name\", \"N/A\"),\n                            \"Tunnel Interface\": edge_rel_properties.get(\"tunnel_interface\", \"N/A\"),\n                            \"Description\": edge_rel_properties.get(\"description\", \"\"),\n                        }\n\n                        formatted_edges.append(\n                            {\n                                \"data\": {\n                                    \"source\": source_id,\n                                    \"target\": target_id,\n                                    **edge_rel_properties,\n                                    \"label\": edge_rel_properties.get(\"label\", edge_rel_properties.get(\"name\", \"\")),\n                                }\n                            }\n                        )\n\n                    if all_node_ids:\n                        all_nodes_query = \"MATCH (n:VPNNode) WHERE n.id IN $all_node_ids RETURN n\"\n                        all_nodes_records = session.run(all_nodes_query, {\"all_node_ids\": list(all_node_ids)})\n                        for record in all_nodes_records:\n                            node_data_neo = record[\"n\"]\n                            node_properties = dict(node_data_neo)\n                            node_id = node_properties.get(\"id\")\n                            if node_id and node_id not in temp_nodes_dict:\n                                lat = node_properties.get(\"latitude\")\n                                lon = node_properties.get(\"longitude\")\n                                x = node_properties.get(\"x\")\n                                y = node_properties.get(\"y\")\n                                pos = None\n\n                                if x is not None and y is not None:\n                                    try:\n                                        pos = {\"x\": float(x), \"y\": float(y)}\n                                    except Exception:\n                                        pos = None\n                                elif lat is not None and lon is not None:\n                                    try:\n                                        x_map, y_map = latlon_to_xy(\n                                            float(lat), float(lon), svg_width=2754, svg_height=1398\n                                        )\n                                        pos = {\"x\": x_map, \"y\": y_map}\n                                    except Exception:\n                                        pos = {\"x\": random.uniform(-100, 100), \"y\": random.uniform(-100, 100)}\n                                else:\n                                    pos = {\"x\": random.uniform(-100, 100), \"y\": random.uniform(-100, 100)}\n\n                                node_obj = {\n                                    \"data\": {\n                                        **node_properties,\n                                        \"is_ha_pair\": node_properties.get(\"is_ha_pair\", False),\n                                        \"node_type\": node_properties.get(\"node_type\", \"DeviceGroup\"),\n                                        \"label\": node_properties.get(\"label\", \"\"),\n                                    }\n                                }\n                                if pos:\n                                    node_obj[\"position\"] = pos\n                                temp_nodes_dict[node_id] = node_obj\n\n                formatted_nodes = list(temp_nodes_dict.values())\n\n            graph_data_response = {\n                \"nodes\": formatted_nodes,\n                \"edges\": formatted_edges,\n                \"meta\": {\n                    \"total_nodes_shown\": len(formatted_nodes),\n                    \"total_edges_shown\": len(formatted_edges),\n                    \"active_tunnels_shown\": sum(\n                        1 for e in formatted_edges if e[\"data\"].get(\"status\", \"\").lower() == \"active\"\n                    ),\n                    \"failed_tunnels_shown\": sum(\n                        1 for e in formatted_edges if e[\"data\"].get(\"status\", \"\").lower() in [\"failed\", \"down\"]\n                    ),\n                    \"planned_tunnels_shown\": sum(\n                        1 for e in formatted_edges if e[\"data\"].get(\"status\", \"\").lower() == \"planned\"\n                    ),\n                    \"ha_pairs_shown\": sum(1 for n in formatted_nodes if n[\"data\"].get(\"is_ha_pair\", False)),\n                    \"focus_node_ids\": list(focus_node_ids),\n                },\n            }\n\n            try:\n                dashboard = VPNDashboard.objects.order_by(\"-last_sync_time\").first()\n                if dashboard:\n                    graph_data_response[\"meta\"][\"last_synced_at\"] = (\n                        dashboard.last_sync_time.isoformat() if dashboard.last_sync_time else None\n                    )\n                    graph_data_response[\"meta\"][\"last_sync_status\"] = dashboard.last_sync_status\n                else:\n                    graph_data_response[\"meta\"][\"last_synced_at\"] = None\n                    graph_data_response[\"meta\"][\"last_sync_status\"] = \"Unknown (No Dashboard Data)\"\n            except Exception as e:\n                logger.warning(f\"Failed to read VPNDashboard for sync time: {e}\")\n                graph_data_response[\"meta\"][\"last_synced_at\"] = None\n                graph_data_response[\"meta\"][\"last_sync_status\"] = \"Error reading status\"\n\n            return Response(graph_data_response)\n\n        except neo4j_exceptions.CypherSyntaxError as e:\n            logger.error(f\"Neo4j Cypher Syntax Error in VPNTopologyNeo4jView: {e}\", exc_info=True)\n            return Response({\"error\": \"Error querying graph database (query syntax problem).\"}, status=500)\n        except neo4j_exceptions.ServiceUnavailable:\n            logger.error(\"Neo4j Service Unavailable during VPN topology query.\", exc_info=True)\n            return Response({\"error\": \"Graph database service unavailable during query.\"}, status=503)\n        except Exception as e:\n            logger.error(f\"Error querying or processing data from Neo4j in VPNTopologyNeo4jView: {e}\", exc_info=True)\n            return Response({\"error\": \"Could not retrieve topology data from graph database.\"}, status=500)\n        finally:\n            if driver:\n                driver.close()\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.pagination","title":"<code>pagination</code>","text":"<p>Custom pagination classes for the Nautobot VPN plugin API.</p>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.pagination.LargeResultsSetPagination","title":"<code>LargeResultsSetPagination</code>","text":"<p>               Bases: <code>PageNumberPagination</code></p> <p>Large pagination class for bulk API requests.</p> <ul> <li>Used for bulk exports or high-performance endpoints.</li> </ul> Source code in <code>nautobot_app_vpn/api/pagination.py</code> <pre><code>class LargeResultsSetPagination(PageNumberPagination):\n    \"\"\"Large pagination class for bulk API requests.\n\n    - Used for bulk exports or high-performance endpoints.\n    \"\"\"\n\n    page_size = 100  # \u2705 Larger page size for bulk operations\n    page_size_query_param = \"page_size\"\n    max_page_size = 500  # \u2705 Allows exporting up to 500 records per request\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.pagination.SmallResultsSetPagination","title":"<code>SmallResultsSetPagination</code>","text":"<p>               Bases: <code>PageNumberPagination</code></p> <p>Smaller pagination for lightweight API endpoints.</p> <ul> <li>Useful for quick-loading small lists.</li> </ul> Source code in <code>nautobot_app_vpn/api/pagination.py</code> <pre><code>class SmallResultsSetPagination(PageNumberPagination):\n    \"\"\"Smaller pagination for lightweight API endpoints.\n\n    - Useful for quick-loading small lists.\n    \"\"\"\n\n    page_size = 5  # \u2705 Minimal results for quick API calls\n    page_size_query_param = \"page_size\"\n    max_page_size = 50  # \u2705 Ensures no overload\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.pagination.StandardResultsSetPagination","title":"<code>StandardResultsSetPagination</code>","text":"<p>               Bases: <code>PageNumberPagination</code></p> <p>Standard pagination for API endpoints.</p> <ul> <li>Supports dynamic page sizes via <code>?page_size=X</code></li> <li>Prevents excessive page loads with <code>max_page_size=100</code></li> <li>Defaults to 25 results per page   for a better balance of performance and usability.</li> </ul> Source code in <code>nautobot_app_vpn/api/pagination.py</code> <pre><code>class StandardResultsSetPagination(PageNumberPagination):\n    \"\"\"Standard pagination for API endpoints.\n\n    - Supports dynamic page sizes via `?page_size=X`\n    - Prevents excessive page loads with `max_page_size=100`\n    - Defaults to 25 results per page\n      for a better balance of performance and usability.\n    \"\"\"\n\n    page_size = 25\n    page_size_query_param = \"page_size\"\n    max_page_size = 200\n    last_page_strings = (\"last\",)\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.permissions","title":"<code>permissions</code>","text":""},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.permissions.IsAdminOrReadOnly","title":"<code>IsAdminOrReadOnly</code>","text":"<p>               Bases: <code>BasePermission</code></p> <p>Allow only staff/superusers to modify data. Read-only access is allowed for everyone.</p> Source code in <code>nautobot_app_vpn/api/permissions.py</code> <pre><code>class IsAdminOrReadOnly(BasePermission):\n    \"\"\"Allow only staff/superusers to modify data.\n    Read-only access is allowed for everyone.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        if request.method in SAFE_METHODS:\n            return True\n        return request.user and (request.user.is_staff or request.user.is_superuser)\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.permissions.IsAuthenticatedOrAdmin","title":"<code>IsAuthenticatedOrAdmin</code>","text":"<p>               Bases: <code>BasePermission</code></p> <p>Allow authenticated users to write. Anonymous users get read-only access.</p> Source code in <code>nautobot_app_vpn/api/permissions.py</code> <pre><code>class IsAuthenticatedOrAdmin(BasePermission):\n    \"\"\"Allow authenticated users to write.\n    Anonymous users get read-only access.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        if request.method in SAFE_METHODS:\n            return True\n        return request.user and request.user.is_authenticated\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.permissions.IsOwnerOrAdmin","title":"<code>IsOwnerOrAdmin</code>","text":"<p>               Bases: <code>BasePermission</code></p> <p>Allow users to modify only objects they own. Admins have full access. Assumes <code>obj.created_by</code> exists; otherwise, denies write access.</p> Source code in <code>nautobot_app_vpn/api/permissions.py</code> <pre><code>class IsOwnerOrAdmin(BasePermission):\n    \"\"\"Allow users to modify only objects they own.\n    Admins have full access.\n    Assumes `obj.created_by` exists; otherwise, denies write access.\n    \"\"\"\n\n    def has_object_permission(self, request, view, obj):\n        if request.method in SAFE_METHODS:\n            return True\n\n        # Fall back to read-only if `created_by` is not defined\n        owner = getattr(obj, \"created_by\", None)\n        if owner is None:\n            return False\n\n        return request.user.is_superuser or owner == request.user\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.serializers","title":"<code>serializers</code>","text":""},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.serializers.NestedTunnelMonitorProfileSerializer","title":"<code>NestedTunnelMonitorProfileSerializer</code>","text":"<p>               Bases: <code>BaseModelSerializer</code></p> <p>Minimal serializer for related TunnelMonitorProfile objects.</p> Source code in <code>nautobot_app_vpn/api/serializers.py</code> <pre><code>class NestedTunnelMonitorProfileSerializer(BaseModelSerializer):\n    \"\"\"Minimal serializer for related TunnelMonitorProfile objects.\"\"\"\n\n    url = serializers.HyperlinkedIdentityField(view_name=\"plugins-api:nautobot_app_vpn-api:tunnelmonitorprofile-detail\")\n\n    class Meta:\n        model = TunnelMonitorProfile\n        fields = [\"id\", \"url\", \"display\", \"name\"]\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.serializers.TunnelMonitorProfileSerializer","title":"<code>TunnelMonitorProfileSerializer</code>","text":"<p>               Bases: <code>BaseModelSerializer</code></p> <p>Serializer for Tunnel Monitor Profiles.</p> Source code in <code>nautobot_app_vpn/api/serializers.py</code> <pre><code>class TunnelMonitorProfileSerializer(BaseModelSerializer):\n    \"\"\"Serializer for Tunnel Monitor Profiles.\"\"\"\n\n    url = serializers.HyperlinkedIdentityField(view_name=\"plugins-api:nautobot_app_vpn-api:tunnelmonitorprofile-detail\")\n    action = ChoiceField(choices=TunnelMonitorActionChoices.choices, required=False)\n\n    class Meta:\n        model = TunnelMonitorProfile\n        fields = [\"id\", \"display\", \"url\", \"name\", \"action\", \"interval\", \"threshold\", \"created\", \"last_updated\"]\n        read_only_fields = [\"id\", \"display\", \"url\", \"created\", \"last_updated\"]\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.viewsets","title":"<code>viewsets</code>","text":""},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.viewsets.IPSECTunnelViewSet","title":"<code>IPSECTunnelViewSet</code>","text":"<p>               Bases: <code>ModelViewSet</code></p> <p>API viewset for IPSec Tunnels.</p> Source code in <code>nautobot_app_vpn/api/viewsets.py</code> <pre><code>class IPSECTunnelViewSet(viewsets.ModelViewSet):\n    \"\"\"API viewset for IPSec Tunnels.\"\"\"\n\n    # &lt;&lt;&lt; UPDATED queryset: Removed bind_interface from select_related &gt;&gt;&gt;\n    queryset = (\n        IPSECTunnel.objects.select_related(\n            \"ike_gateway\",\n            \"ipsec_crypto_profile\",\n            \"status\",\n            \"tunnel_interface\",\n            \"monitor_profile\",\n        )\n        .prefetch_related(\n            \"devices\",\n            \"proxy_ids\",\n        )\n        .order_by(\"name\")\n        .distinct()\n    )\n\n    serializer_class = IPSECTunnelSerializer\n    permission_classes = [IsAdminOrReadOnly]\n    filter_backends = [DjangoFilterBackend, filters.OrderingFilter, filters.SearchFilter]\n    filterset_class = IPSECTunnelFilterSet\n\n    ordering_fields = [\n        \"name\",\n        \"ike_gateway__name\",\n        \"ipsec_crypto_profile__name\",\n        \"tunnel_interface__name\",\n        \"status__name\",\n        \"enable_tunnel_monitor\",\n        \"monitor_destination_ip\",\n    ]\n    search_fields = [\n        \"name\",\n        \"description\",\n        \"ike_gateway__name\",\n        \"ipsec_crypto_profile__name\",\n        \"tunnel_interface__name\",\n        \"monitor_destination_ip\",\n    ]\n    pagination_class = StandardResultsSetPagination\n\n    def perform_create(self, serializer):\n        serializer.save()\n\n    def perform_update(self, serializer):\n        serializer.save()\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.viewsets.TunnelMonitorProfileViewSet","title":"<code>TunnelMonitorProfileViewSet</code>","text":"<p>               Bases: <code>ModelViewSet</code></p> <p>API viewset for Tunnel Monitor Profiles.</p> Source code in <code>nautobot_app_vpn/api/viewsets.py</code> <pre><code>class TunnelMonitorProfileViewSet(viewsets.ModelViewSet):\n    \"\"\"API viewset for Tunnel Monitor Profiles.\"\"\"\n\n    queryset = TunnelMonitorProfile.objects.all().order_by(\"name\")\n    serializer_class = TunnelMonitorProfileSerializer\n    permission_classes = [IsAdminOrReadOnly]\n    filter_backends = [DjangoFilterBackend, filters.OrderingFilter, filters.SearchFilter]  # Uncommented filter_backends\n    filterset_class = TunnelMonitorProfileFilterSet\n    ordering_fields = [\"name\", \"action\", \"interval\", \"threshold\"]\n    search_fields = [\"name\"]\n    pagination_class = StandardResultsSetPagination\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.viewsets.VPNTopologyFilterOptionsView","title":"<code>VPNTopologyFilterOptionsView</code>","text":"<p>               Bases: <code>APIView</code></p> <p>API view to return distinct filter options for countries, platforms, roles, etc., primarily based on data currently associated with IPSECTunnels in Nautobot's relational DB.</p> Source code in <code>nautobot_app_vpn/api/viewsets.py</code> <pre><code>class VPNTopologyFilterOptionsView(APIView):\n    \"\"\"API view to return distinct filter options for countries, platforms, roles, etc.,\n    primarily based on data currently associated with IPSECTunnels in Nautobot's relational DB.\n    \"\"\"\n\n    permission_classes = [IsAuthenticated]\n\n    def _get_device_country_from_name(self, device_name):\n        \"\"\"Derives country from device name based on 'CODE-...' convention.\"\"\"\n        if device_name:\n            parts = device_name.split(\"-\")\n            if parts:\n                return parts[0].upper()\n        return None\n\n    def get(self, request):\n        logger.debug(f\"Filter options GET request from user {request.user}\")\n        countries = set()\n        ike_versions = set()\n        statuses = set()\n        tunnel_roles = set()\n        devices_map = {}\n        locations = set()\n        platforms_set = set()  # store (id, name)\n\n        tunnels_qs = IPSECTunnel.objects.select_related(\n            \"ike_gateway\", \"status\", \"ike_gateway__local_platform\", \"ike_gateway__peer_platform\"\n        ).prefetch_related(\n            \"ike_gateway__local_devices__platform\",\n            \"ike_gateway__local_devices__location\",\n            \"ike_gateway__local_devices__role\",\n            \"ike_gateway__peer_devices__platform\",\n            \"ike_gateway__peer_devices__location\",\n            \"ike_gateway__peer_devices__role\",\n        )\n\n        for tunnel in tunnels_qs:\n            if tunnel.status and tunnel.status.name:\n                statuses.add(tunnel.status.name)\n            if tunnel.role:\n                tunnel_roles.add(str(tunnel.role))\n            gw = tunnel.ike_gateway\n            if gw:\n                if gw.ike_version:\n                    ike_versions.add(str(gw.ike_version))\n\n                for plat in [gw.local_platform, gw.peer_platform]:\n                    if plat:\n                        platforms_set.add((plat.id, plat.name))\n\n                for dev_group in [gw.local_devices.all(), gw.peer_devices.all()]:\n                    for dev in dev_group:\n                        if dev and dev.name:\n                            devices_map[str(dev.pk)] = dev.name\n                            country = self._get_device_country_from_name(dev.name)\n                            if country:\n                                countries.add(country)\n                        if dev and dev.location and dev.location.name:\n                            locations.add(dev.location.name)\n                        if dev and dev.platform:\n                            platforms_set.add((dev.platform.id, dev.platform.name))\n\n        all_defined_platforms = Platform.objects.all().values(\"id\", \"name\").distinct()\n        for plat in all_defined_platforms:\n            platforms_set.add((plat[\"id\"], plat[\"name\"]))\n\n        platforms_out = [\n            {\"id\": pid, \"name\": n} for pid, n in sorted(platforms_set, key=lambda x: (x[1] or \"\", x[0] or \"\")) if n\n        ]\n\n        return Response(\n            {\n                \"countries\": sorted(filter(None, countries)),\n                \"ike_versions\": sorted(filter(None, ike_versions)),\n                \"statuses\": sorted(filter(None, statuses)),\n                \"roles\": sorted(filter(None, tunnel_roles)),\n                \"tunnel_roles\": sorted(filter(None, tunnel_roles)),\n                \"devices\": [\n                    {\"id\": pk, \"label\": name} for pk, name in sorted(devices_map.items(), key=lambda item: item[1])\n                ],\n                \"locations\": sorted(filter(None, locations)),\n                \"platforms\": platforms_out,\n            }\n        )\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.viewsets.VPNTopologyNeo4jView","title":"<code>VPNTopologyNeo4jView</code>","text":"<p>               Bases: <code>APIView</code></p> <p>API view to return VPN topology nodes and edges for visualization, sourced from Neo4j, with support for filtering.</p> Source code in <code>nautobot_app_vpn/api/viewsets.py</code> <pre><code>class VPNTopologyNeo4jView(APIView):\n    \"\"\"API view to return VPN topology nodes and edges for visualization,\n    sourced from Neo4j, with support for filtering.\n    \"\"\"\n\n    permission_classes = [IsAuthenticated]\n\n    def _build_cypher_queries_and_params(self, filters_dict):\n        \"\"\"Builds Cypher queries and parameters for fetching nodes and edges based on request filters.\n        Returns: (nodes_query_string, edges_query_string, query_parameters_dict)\n        \"\"\"\n        query_params = {}\n\n        node_match_clause = \"MATCH (n:VPNNode)\"\n        node_where_clauses = []\n\n        if filters_dict.get(\"country\"):\n            node_where_clauses.append(\"toLower(n.country) = toLower($country)\")\n            query_params[\"country\"] = filters_dict[\"country\"]\n\n        if filters_dict.get(\"platform\"):\n            platform_val = filters_dict[\"platform\"]\n            node_where_clauses.append(\"toLower(n.platform_name) CONTAINS toLower($platform)\")\n            query_params[\"platform\"] = platform_val\n\n        if filters_dict.get(\"location\"):\n            node_where_clauses.append(\"toLower(n.location_name) CONTAINS toLower($location)\")\n            query_params[\"location\"] = filters_dict[\"location\"]\n\n        if filters_dict.get(\"device\"):\n            val = str(filters_dict[\"device\"]).strip()\n            node_where_clauses.append(\n                \"(\"\n                \"toLower($device_name) IN [dev IN n.device_names | toLower(dev)] \"\n                \"OR $device_name IN n.nautobot_device_pks \"\n                \"OR toLower(n.label) CONTAINS toLower($device_name)\"\n                \")\"\n            )\n            query_params[\"device_name\"] = val\n\n        if filters_dict.get(\"role\"):\n            node_where_clauses.append(\"toLower(n.role) = toLower($device_role)\")\n            query_params[\"device_role\"] = filters_dict[\"role\"]\n\n        nodes_query_string = node_match_clause\n        if node_where_clauses:\n            nodes_query_string += \" WHERE \" + \" AND \".join(node_where_clauses)\n        nodes_query_string += \" RETURN n\"\n\n        edges_query_string = (\n            \"MATCH (n1:VPNNode)-[r:TUNNEL]-&gt;(n2:VPNNode) WHERE n1.id IN $node_ids AND n2.id IN $node_ids\"\n        )\n        edge_filter_conditions = []\n\n        if filters_dict.get(\"status\"):\n            edge_filter_conditions.append(\"toLower(r.status) = toLower($tunnel_status)\")\n            query_params[\"tunnel_status\"] = filters_dict[\"status\"]\n\n        if filters_dict.get(\"ike_version\"):\n            edge_filter_conditions.append(\"toLower(r.ike_version) = toLower($ike_version)\")\n            query_params[\"ike_version\"] = filters_dict[\"ike_version\"]\n\n        if filters_dict.get(\"role\"):  # Use \"role\" consistently\n            edge_filter_conditions.append(\"toLower(r.role) = toLower($tunnel_role)\")\n            query_params[\"tunnel_role\"] = filters_dict[\"role\"]\n\n        if edge_filter_conditions:\n            edges_query_string += \" AND \" + \" AND \".join(edge_filter_conditions)\n\n        edges_query_string += \" RETURN n1.id AS source, n2.id AS target, r AS properties\"\n\n        return nodes_query_string, edges_query_string, query_params\n\n    def get(self, request):\n        logger.info(f\"Neo4j VPN Topology GET request from user {request.user} with filters: {request.GET.dict()}\")\n\n        if not all(hasattr(settings, attr) for attr in [\"NEO4J_URI\", \"NEO4J_USER\", \"NEO4J_PASSWORD\"]):\n            logger.error(\"Neo4j connection settings are not fully configured in Nautobot settings.\")\n            return Response({\"error\": \"Graph database service is not configured.\"}, status=503)\n\n        driver = None\n        try:\n            driver = GraphDatabase.driver(settings.NEO4J_URI, auth=(settings.NEO4J_USER, settings.NEO4J_PASSWORD))\n            driver.verify_connectivity()\n        except Exception as e:\n            logger.error(f\"Failed to connect to Neo4j for topology view: {e}\", exc_info=True)\n            return Response({\"error\": \"Could not connect to graph database.\"}, status=503)\n\n        formatted_nodes = []\n        formatted_edges = []\n\n        request_filters = request.GET.dict()\n        nodes_cypher, edges_cypher, query_params_base = self._build_cypher_queries_and_params(request_filters)\n\n        try:\n            with driver.session(database=getattr(settings, \"NEO4J_DATABASE\", \"neo4j\")) as session:\n                logger.debug(f\"Executing Neo4j Node Query: {nodes_cypher} with params: {query_params_base}\")\n                node_records = session.run(nodes_cypher, query_params_base)\n                focus_node_ids = set()\n                temp_nodes_dict = {}\n\n                for record in node_records:\n                    node_data_neo = record[\"n\"]\n                    node_properties = dict(node_data_neo)\n                    node_id = node_properties.get(\"id\")\n                    if node_id:\n                        focus_node_ids.add(node_id)\n                        if node_id not in temp_nodes_dict:\n                            lat = node_properties.get(\"latitude\")\n                            lon = node_properties.get(\"longitude\")\n                            x = node_properties.get(\"x\")\n                            y = node_properties.get(\"y\")\n                            pos = None\n\n                            if x is not None and y is not None:\n                                try:\n                                    pos = {\"x\": float(x), \"y\": float(y)}\n                                except Exception:\n                                    pos = None\n                            elif lat is not None and lon is not None:\n                                try:\n                                    x_map, y_map = latlon_to_xy(float(lat), float(lon), svg_width=2754, svg_height=1398)\n                                    pos = {\"x\": x_map, \"y\": y_map}\n                                except Exception:\n                                    pos = {\"x\": random.uniform(-100, 100), \"y\": random.uniform(-100, 100)}\n                            else:\n                                pos = {\"x\": random.uniform(-100, 100), \"y\": random.uniform(-100, 100)}\n\n                            node_obj = {\n                                \"data\": {\n                                    **node_properties,\n                                    \"is_ha_pair\": node_properties.get(\"is_ha_pair\", False),\n                                    \"node_type\": node_properties.get(\"node_type\", \"DeviceGroup\"),\n                                    \"label\": node_properties.get(\"label\", \"\"),\n                                }\n                            }\n                            if pos:\n                                node_obj[\"position\"] = pos\n                            temp_nodes_dict[node_id] = node_obj\n\n                if focus_node_ids:\n                    edge_query = \"\"\"\n                        MATCH (n1:VPNNode)-[r:TUNNEL]-&gt;(n2:VPNNode)\n                        WHERE n1.id IN $focus_node_ids OR n2.id IN $focus_node_ids\n                        RETURN n1.id AS source, n2.id AS target, r AS properties\n                    \"\"\"\n                    logger.debug(f\"Executing Neo4j Edge Query: {edge_query} with focus_node_ids: {focus_node_ids}\")\n                    edge_records = session.run(edge_query, {\"focus_node_ids\": list(focus_node_ids)})\n\n                    all_node_ids = set(focus_node_ids)  # Start with focus nodes\n\n                    for record in edge_records:\n                        source_id = record[\"source\"]\n                        target_id = record[\"target\"]\n                        all_node_ids.add(source_id)\n                        all_node_ids.add(target_id)\n\n                        edge_rel_properties = dict(record[\"properties\"])\n                        if \"nautobot_tunnel_pk\" in edge_rel_properties:\n                            edge_rel_properties[\"id\"] = f\"tunnel_{edge_rel_properties['nautobot_tunnel_pk']}\"\n                        else:\n                            edge_rel_properties[\"id\"] = f\"edge_{record['properties'].element_id}\"\n\n                        edge_rel_properties[\"tooltip_details\"] = {\n                            \"Tunnel Name\": edge_rel_properties.get(\"name\", \"N/A\"),\n                            \"Status\": edge_rel_properties.get(\"status\", \"N/A\"),\n                            \"Role\": edge_rel_properties.get(\"role\", \"N/A\"),\n                            \"IKE Gateway\": edge_rel_properties.get(\"ike_gateway_name\", \"N/A\"),\n                            \"IKE Version\": edge_rel_properties.get(\"ike_version\", \"N/A\"),\n                            \"IPsec Profile\": edge_rel_properties.get(\"ipsec_profile_name\", \"N/A\"),\n                            \"Tunnel Interface\": edge_rel_properties.get(\"tunnel_interface\", \"N/A\"),\n                            \"Description\": edge_rel_properties.get(\"description\", \"\"),\n                        }\n\n                        formatted_edges.append(\n                            {\n                                \"data\": {\n                                    \"source\": source_id,\n                                    \"target\": target_id,\n                                    **edge_rel_properties,\n                                    \"label\": edge_rel_properties.get(\"label\", edge_rel_properties.get(\"name\", \"\")),\n                                }\n                            }\n                        )\n\n                    if all_node_ids:\n                        all_nodes_query = \"MATCH (n:VPNNode) WHERE n.id IN $all_node_ids RETURN n\"\n                        all_nodes_records = session.run(all_nodes_query, {\"all_node_ids\": list(all_node_ids)})\n                        for record in all_nodes_records:\n                            node_data_neo = record[\"n\"]\n                            node_properties = dict(node_data_neo)\n                            node_id = node_properties.get(\"id\")\n                            if node_id and node_id not in temp_nodes_dict:\n                                lat = node_properties.get(\"latitude\")\n                                lon = node_properties.get(\"longitude\")\n                                x = node_properties.get(\"x\")\n                                y = node_properties.get(\"y\")\n                                pos = None\n\n                                if x is not None and y is not None:\n                                    try:\n                                        pos = {\"x\": float(x), \"y\": float(y)}\n                                    except Exception:\n                                        pos = None\n                                elif lat is not None and lon is not None:\n                                    try:\n                                        x_map, y_map = latlon_to_xy(\n                                            float(lat), float(lon), svg_width=2754, svg_height=1398\n                                        )\n                                        pos = {\"x\": x_map, \"y\": y_map}\n                                    except Exception:\n                                        pos = {\"x\": random.uniform(-100, 100), \"y\": random.uniform(-100, 100)}\n                                else:\n                                    pos = {\"x\": random.uniform(-100, 100), \"y\": random.uniform(-100, 100)}\n\n                                node_obj = {\n                                    \"data\": {\n                                        **node_properties,\n                                        \"is_ha_pair\": node_properties.get(\"is_ha_pair\", False),\n                                        \"node_type\": node_properties.get(\"node_type\", \"DeviceGroup\"),\n                                        \"label\": node_properties.get(\"label\", \"\"),\n                                    }\n                                }\n                                if pos:\n                                    node_obj[\"position\"] = pos\n                                temp_nodes_dict[node_id] = node_obj\n\n                formatted_nodes = list(temp_nodes_dict.values())\n\n            graph_data_response = {\n                \"nodes\": formatted_nodes,\n                \"edges\": formatted_edges,\n                \"meta\": {\n                    \"total_nodes_shown\": len(formatted_nodes),\n                    \"total_edges_shown\": len(formatted_edges),\n                    \"active_tunnels_shown\": sum(\n                        1 for e in formatted_edges if e[\"data\"].get(\"status\", \"\").lower() == \"active\"\n                    ),\n                    \"failed_tunnels_shown\": sum(\n                        1 for e in formatted_edges if e[\"data\"].get(\"status\", \"\").lower() in [\"failed\", \"down\"]\n                    ),\n                    \"planned_tunnels_shown\": sum(\n                        1 for e in formatted_edges if e[\"data\"].get(\"status\", \"\").lower() == \"planned\"\n                    ),\n                    \"ha_pairs_shown\": sum(1 for n in formatted_nodes if n[\"data\"].get(\"is_ha_pair\", False)),\n                    \"focus_node_ids\": list(focus_node_ids),\n                },\n            }\n\n            try:\n                dashboard = VPNDashboard.objects.order_by(\"-last_sync_time\").first()\n                if dashboard:\n                    graph_data_response[\"meta\"][\"last_synced_at\"] = (\n                        dashboard.last_sync_time.isoformat() if dashboard.last_sync_time else None\n                    )\n                    graph_data_response[\"meta\"][\"last_sync_status\"] = dashboard.last_sync_status\n                else:\n                    graph_data_response[\"meta\"][\"last_synced_at\"] = None\n                    graph_data_response[\"meta\"][\"last_sync_status\"] = \"Unknown (No Dashboard Data)\"\n            except Exception as e:\n                logger.warning(f\"Failed to read VPNDashboard for sync time: {e}\")\n                graph_data_response[\"meta\"][\"last_synced_at\"] = None\n                graph_data_response[\"meta\"][\"last_sync_status\"] = \"Error reading status\"\n\n            return Response(graph_data_response)\n\n        except neo4j_exceptions.CypherSyntaxError as e:\n            logger.error(f\"Neo4j Cypher Syntax Error in VPNTopologyNeo4jView: {e}\", exc_info=True)\n            return Response({\"error\": \"Error querying graph database (query syntax problem).\"}, status=500)\n        except neo4j_exceptions.ServiceUnavailable:\n            logger.error(\"Neo4j Service Unavailable during VPN topology query.\", exc_info=True)\n            return Response({\"error\": \"Graph database service unavailable during query.\"}, status=503)\n        except Exception as e:\n            logger.error(f\"Error querying or processing data from Neo4j in VPNTopologyNeo4jView: {e}\", exc_info=True)\n            return Response({\"error\": \"Could not retrieve topology data from graph database.\"}, status=500)\n        finally:\n            if driver:\n                driver.close()\n</code></pre>"},{"location":"dev/code_reference/api/#nautobot_app_vpn.api.viewsets.latlon_to_xy","title":"<code>latlon_to_xy(lat, lon, svg_width=2754, svg_height=1398)</code>","text":"<p>Map latitude and longitude to SVG x, y coordinates. Assumes equirectangular projection.</p> Source code in <code>nautobot_app_vpn/api/viewsets.py</code> <pre><code>def latlon_to_xy(lat, lon, svg_width=2754, svg_height=1398):\n    \"\"\"Map latitude and longitude to SVG x, y coordinates.\n    Assumes equirectangular projection.\n    \"\"\"\n    x = (lon + 180) * (svg_width / 360.0)\n    y = (90 - lat) * (svg_height / 180.0)\n    return x, y\n</code></pre>"},{"location":"dev/code_reference/package/","title":"Package","text":""},{"location":"dev/code_reference/package/#nautobot_app_vpn","title":"<code>nautobot_app_vpn</code>","text":"<p>App declaration for nautobot_app_vpn.</p>"},{"location":"dev/code_reference/package/#nautobot_app_vpn.Nautobot_App_VpnConfig","title":"<code>Nautobot_App_VpnConfig</code>","text":"<p>               Bases: <code>NautobotAppConfig</code></p> <p>App configuration for the nautobot_app_vpn app.</p> Source code in <code>nautobot_app_vpn/__init__.py</code> <pre><code>class Nautobot_App_VpnConfig(NautobotAppConfig):\n    \"\"\"App configuration for the nautobot_app_vpn app.\"\"\"\n\n    name = \"nautobot_app_vpn\"\n    verbose_name = \"VPN\"\n    version = __version__\n    author = \"ISS World Services @Powered by NOC\"\n    description = \"Virtual Private Network\"\n    base_url = \"nautobot_app_vpn\"\n    required_settings = []\n    min_version = \"2.4.0\"\n    max_version = \"2.9999\"\n    default_settings = {}\n    caching_config = {}\n    docs_view_name = \"plugins:nautobot_app_vpn:docs\"\n    jobs = \"nautobot_app_vpn.jobs\"\n\n    def ready(self):\n        super().ready()\n        # \u2705 Register jobs only when registry is ready\n        from nautobot.apps import jobs\n\n        from .jobs.sync_neo4j_job import SyncNeo4jJob\n\n        jobs.register_jobs(\n            SyncNeo4jJob,\n        )\n</code></pre>"},{"location":"user/app_getting_started/","title":"Getting Started with the App","text":"<p>This document provides a step-by-step tutorial on how to get the App going and how to use it.</p>"},{"location":"user/app_getting_started/#install-the-app","title":"Install the App","text":"<p>To install the App, please follow the instructions detailed in the Installation Guide.</p>"},{"location":"user/app_getting_started/#first-steps-with-the-app","title":"First steps with the App","text":"<p>Developer Note - Remove Me!</p> <p>What (with screenshots preferably) does it look like to perform the simplest workflow within the App once installed?</p>"},{"location":"user/app_getting_started/#what-are-the-next-steps","title":"What are the next steps?","text":"<p>Developer Note - Remove Me!</p> <p>After taking the first steps, what else could the users look at doing.</p> <p>You can check out the Use Cases section for more examples.</p>"},{"location":"user/app_overview/","title":"App Overview","text":"<p>This document provides an overview of the App including critical information and important considerations when applying it to your Nautobot environment.</p> <p>Note</p> <p>Throughout this documentation, the terms \"app\" and \"plugin\" will be used interchangeably.</p>"},{"location":"user/app_overview/#description","title":"Description","text":""},{"location":"user/app_overview/#audience-user-personas-who-should-use-this-app","title":"Audience (User Personas) - Who should use this App?","text":"<p>Developer Note - Remove Me!</p> <p>Who is this meant for/ who is the common user of this app?</p>"},{"location":"user/app_overview/#authors-and-maintainers","title":"Authors and Maintainers","text":"<p>Developer Note - Remove Me!</p> <p>Add the team and/or the main individuals maintaining this project. Include historical maintainers as well.</p>"},{"location":"user/app_overview/#nautobot-features-used","title":"Nautobot Features Used","text":"<p>Developer Note - Remove Me!</p> <p>What is shown today in the Installed Apps page in Nautobot. What parts of Nautobot does it interact with, what does it add etc. ?</p>"},{"location":"user/app_overview/#extras","title":"Extras","text":"<p>Developer Note - Remove Me!</p> <p>Custom Fields - things like which CFs are created by this app? Jobs - are jobs, if so, which ones, installed by this app?</p>"},{"location":"user/app_use_cases/","title":"Using the App","text":"<p>This document describes common use-cases and scenarios for this App.</p>"},{"location":"user/app_use_cases/#general-usage","title":"General Usage","text":""},{"location":"user/app_use_cases/#use-cases-and-common-workflows","title":"Use-cases and common workflows","text":""},{"location":"user/app_use_cases/#screenshots","title":"Screenshots","text":"<p>Developer Note - Remove Me!</p> <p>Ideally captures every view exposed by the App.\u00a0Should include a relevant dataset.</p>"},{"location":"user/external_interactions/","title":"External Interactions","text":"<p>This document describes external dependencies and prerequisites for this App to operate, including system requirements, API endpoints, interconnection or integrations to other applications or services, and similar topics.</p> <p>Developer Note - Remove Me!</p> <p>Optional page, remove if not applicable.</p>"},{"location":"user/external_interactions/#external-system-integrations","title":"External System Integrations","text":""},{"location":"user/external_interactions/#from-the-app-to-other-systems","title":"From the App to Other Systems","text":""},{"location":"user/external_interactions/#from-other-systems-to-the-app","title":"From Other Systems to the App","text":""},{"location":"user/external_interactions/#nautobot-rest-api-endpoints","title":"Nautobot REST API endpoints","text":"<p>Developer Note - Remove Me!</p> <p>API documentation in this doc - including python request examples, curl examples, postman collections referred etc.</p>"},{"location":"user/faq/","title":"Frequently Asked Questions","text":""}]}